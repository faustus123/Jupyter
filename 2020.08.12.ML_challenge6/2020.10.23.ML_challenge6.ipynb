{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge Problem 6 Part 3\n",
    "\n",
    "UPDATE: Here I was trying to use an RNN to identify pulses. I did not get terribly far due mainly to the question on how to define the labels. I initially thought to insert single samples into the LSTM model and have it report the pulse sometime after seeing it pass. I went partway down the path and then learned about the TimeSeriesGenerator class in Keras so I backtracked and started playing with that. As I read and thought about it more, it seemed that the primary use of RNN's was to take a stream of information and predict the next element in that stream. The TimeSeriesGenerator allows one to define a model with multiple input samples (say 16) and have it \"stride\" through a larger list of samples (say 128). This seemed attractive due being able to fit an entire pulse into the inputs at once. Ultimately, this seemed very similar to a CNN and in fact, Kishan had recently suggested a Conv1D. I've decided to abandon the RNN idea for now and switch to a conv1D. This leaves the bottom of this notebook in a very broken state which is why I'm leaving this note to explain it.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Here I try approaching the problem using an RNN. The idea here is to feed a continuous stream of samples through the RNN and have it recognize when a pulse has passed. The tricky part here is going to be how to generate the labels. It would not make much sense to specify the labels at the identified time of the pulse for a couple of reasons. One being that the samples past the pulse time should be used to help get the most accurate time. The other being that the identified pulse time is a floating point number somewhere in between samples.\n",
    "\n",
    "The first thing to do here is to read all of the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of waveforms: 1000\n"
     ]
    }
   ],
   "source": [
    "# Read the full data file into a dataframe\n",
    "# This file does not have a header so we define the column names here explicitly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_FILE  = '/home/davidl/work2/2020.08.12.ML_challenge6/Aug_2020_ML_train.csv'\n",
    "\n",
    "# Columns in input file. First 5 are labels\n",
    "names = ['ped', 'A1', 'A2', 't1', 't2']\n",
    "\n",
    "# Next 128 are features (waveform)\n",
    "for i in range(0,128): names.append('s%03d' % i)\n",
    "\n",
    "# Read file and print how many waveforms are found\n",
    "df = pd.read_csv(TRAIN_FILE, names=names)\n",
    "print('Number of waveforms: %d' % len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert sample to time\n",
    "Next, we need to figure out how to convert between sample number and the labeled times. What we really need is a way to convert a time into a sample number. This will allow us to know which samples are closest to the labeled times. This is needed so we can try training the RNN when to \"emit\" the time after a pulse has passed.\n",
    "\n",
    "To do this, we'll take the minimum sample from the waveform (i.e. largest negative value representing the peak) and plot that vs. the labeled time, but only for single pulse waveforms. Do a linear regression on this to get the conversion values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-ozl2o08l because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Parameters: slope=0.985705  intercept=0.301877\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAfz0lEQVR4nO3de3xddZnv8c+Tll5CkdKCmUKbvZGLlwELtihQBpoC6giDvBAYNThFOQRHQBRwwJMX5+houAiiiAiTUaD42jMFAeUmqIdpOChQTsLFIlW5mJQWsEBboE2hQ/OcP9ZKu5PuvbOS7rX2ZX3fr9d+Za/9Wzv74Ufy5OlvrfUsc3dERCQ9GiodgIiIJEuJX0QkZZT4RURSRolfRCRllPhFRFJmfKUDiGLXXXf1bDZb6TAK2rBhAzvuuGOlw6gamo+tNBdDaT6GSmI+enp6XnX33Ya/XhOJP5vN0t3dXekwCurq6mL+/PmVDqNqaD620lwMpfkYKon5MLO+Qq9rqUdEJGWU+EVEUkaJX0QkZZT4RURSRolfRCRllPhFRKpMLpcjm83S0NBANpsll8uV9fvXxOmcIiJpkcvlaGtro7+/H4C+vj7a2toAaG1tLctnqOIXEaki7e3t9Pf380XgWWAvoL+/n/b29rJ9hip+EZEqMtDXR/5dUp4FDFixYkXZPkMVv4hItTjjDIql9+bm5rJ9TKwVv5lNBX4M7Ac48AXgT8DNQBboBU5297VxxiEiUtX+8AfYb7+CQ38LNDY20tHRUbaPi7vivwq4z93fB8wGlgMXAve7+z7A/eG2iEj6uMMnPlEw6d/T2EgDsCGTobOzs2wHdiHGit/MdgYOB04FcPdNwCYz+yQwP9xtEdAFXBBXHCIi1ehdy5ZBS0vhwT//mWP22YeBmD7b4rrZupkdAHQCTxNU+z3AOcAqd58a7mPA2sHtYe9vA9oAmpqa5ixevDiWOLfX+vXrmTJlSqXDqBqaj600F0NpPgK2eTNzTzuNHfu2bZz5wokn8tyZZ5bts1paWnrcfe42McSY+OcCjwDz3H2pmV0FvAGcnZ/ozWytu+9S6nvNnTvX1Za5Nmg+ttJcDKX5gGfnz2fvBx4oPPjiizBjRlk/z8wKJv441/hXAivdfWm4fSvwIeCvZjYjDGoGsDrGGEREKm/NGjArmPQf+8xngrX+Mif9UmJL/O7+MvCCmb03fOlIgmWfO4GF4WsLgTviikFEpOIOOQSmTy84tDNwwkMPJRsP8V/AdTaQM7MJwPPA5wn+2NxiZqcBfcDJMccgIpK8556DvfcuOPQr4KkrruCN88/nzTJemBVVrInf3Z8AtllfIqj+RUTq08SJsGlTwaF3AW8CV4Tb5bwwKypduSsiUi4PPwxmBZP+8o9/nB0bG3kz77VyX5gVlRK/iEg5mMGhhxYe27SJ9997L52dnWQyGcyMCRMmlP3CrKiU+EVEtsettwZJv5BrrgnO2NlhByBoq9zb28vAwAD7779/RZI+qDuniMjYuENDidp5YKD4H4QKU8UvIjJal19ePOnffXfwR6FKkz6o4hcRie7tt2HSpOLjMXVCKDdV/CIiUZx+evGk/9hjNZP0QRW/iEhpa9YUvfKWd78b/vrXZOMpA1X8IiLFlGi3wIoVNZn0QYlfRGRbzz0XHJx95JFtx44+OljWmTUr+bjKREs9IiL5Jk0KDuIW8vrr8K53JRtPDFTxi4hAUN2bFU76X/lKUOXXQdIHVfwiIqXPud+0acuVt/VCFb+IpNdttxVP+j/84ZB2C/VEFb+IpE8Nt1soB1X8IpIuV1xR0+0WykEVv4ikQ520WygHVfwiUv9KtVvo6UlV0gdV/CJSz0q1W9htN1i9Otl4qoQqfhGpT4ceWrrdQkqTPijxi0i9ef754ODsww9vO1YH7RbKQUs9IlI/UtBuoRxU8YtI7SvVbuGcc+qq3UI5qOIXkdqWsnYL5aCKX0RqU0rbLZSDKn4RqS0pb7dQDqr4RaR2lGq3cNddqWi3UA6q+EWk+qndQlmp4heR6tbWpnYLZaaKX0SqU6l2C7vuCq+8kmw8dUQVv4hUn1LtFvr6lPS3kxK/iFSPUu0WjjoqWNZpbk4+rjqjpR4RqQ6TJ8NbbxUeW7cOdt450XDqmSp+EamswXYLhZL+YLsFJf2yUsUvIpWjdgsVEWvFb2a9ZrbMzJ4ws+7wtWlm9hszeyb8ukucMYhIFSrVbuHqq9VuIWZJVPwt7v5q3vaFwP3ufqmZXRhuX5BAHCJSaWq3UBUqscb/SWBR+HwRcHwFYhCRhM26+Wa1W6gS5jFe9WZmfwHWAg78m7t3mtk6d58ajhuwdnB72HvbgDaApqamOYsXL44tzu2xfv16pkyZUukwqobmYyvNRcA2beKIj32s6HjXkiUJRlM9kvj5aGlp6XH3udsMuHtsD2CP8Ou7gSeBw4F1w/ZZO9L3mTNnjlerJUuWVDqEqqL52Epz4e6nn+4e1PLbPnp6Kh1dRSXx8wF0e4GcGusav7uvCr+uNrOfAx8G/mpmM9z9JTObAaT3jsci9UrtFqpabGv8Zrajme00+Bz4KPAUcCewMNxtIXBHXDGISAXMm6d2C1UuzoO7TcBvzexJ4FHgHne/D7gUONrMngGOCrdFpNYNtlt46KFtx446KljLV7uFqhDbUo+7Pw/MLvD6a8CRcX2uiFRAlHYLXV1JRiQlqGWDiIxdqXYLX/6y2i1UKbVsEJGxUbuFmqWKX0RGR+0Wap4qfhGJRu0W6oYqfhEZ2RVXqN1CHVHFLyLFbdoEEycWH9eNzmtSyYrfzBrM7NCkghGRKtLWVjzp9/Qo6dewkhW/uw+Y2TXAgQnFIyKVtnYtTJtWeEztFupClDX++83sU2EnTRGpZ/PmFU/6ardQN6Ik/jOAnwGbzOwNM3vTzN6IOS4RSVKpdgtHHhks66jdQt0Y8eCuu++URCAiUiGNjbBxY+GxwXYLUldGrPgtcIqZXRRuzzKzD8cfmojEarDdQqGkr3YLdS3K6Zw/AgaABcC3gPXANcBBMcYlInFSu4VUi7LG/xF3PxN4C8Dd1wITYo1KROKhdgtCtIr/v81sHMF9czGz3Qj+BSAitULtFiRPlIr/B8DPgSYz6wB+C1wca1QiUj7f/W7xpH/nnWq3kEJRzurJmVkPW2+ecry7L483LBHZbmq3IEVEbdLWCIwL958cXzgiUhZqtyAljFjxm9n/Ak4CbgMMuMHMfubu3447OBEZpVLtFqZPh1dfTTYeqUpRDu62ArPd/S0AM7sUeAJQ4hepJvPmFb7yFoJ2C7ryVkJRlnpeBCblbU8EVsUTjoiM2l/+onYLMipFK34zu5rgFM7XgT+Y2W/C7aOBR5MJT0RKUrsFGYNSSz3d4dcegtM5B3XFFo2IRLN0KRx8cOGxL38Zrroq2XikphRN/O6+KMlARCQitVuQ7RSlSduxZva4ma1RW2aRCirVbuEHP1C7BYksylk93wdOAJa56+RfkcSp3YKUWZSzel4AnlLSF6mAK69UuwUpuygV/78AvzSzB4C3B1909ytji0ok7dRuQWIUpeLvAPoJzuXfKe8hInE444ziSb+7W0lftluUin93d98v9khE0k7tFiQhUSr+X5rZR2OPRCTN5s0rnvT7+pT0payiJP5/Bu4zs406nVOkzEq1W1iwQO0WJBZR+vFrPV8kDmq3IBUS5QKuwws9kghOpC4tXRpU+YWS/tlnB1W+kr7EKMrB3a/lPZ8EfJigf8+CWCISqWdqtyBVYMSK393/Ie9xNLAfsDb+0ETqyO23q92CVI0oFf9wK4H3R93ZzMYRdPpc5e7HmtmewGJgOsG/HD7n7pvGEIdI9VO7BalCUdb4rzazH4SPHwIPAo+N4jPOAfJvzn4Z8D1335vgXw6njSZgkVox85Zbiif9O+5QuwWpmCgVf3fe83eA/3T330X55mY2EziG4Orfc83MCI4NfDbcZRHwDeDaqAGLVL2w3cLexcZ15a1UmMXZe83MbgUuIWjxcD5wKvBIWO1jZrOAewtdGWxmbUAbQFNT05zFixfHFuf2WL9+PVOmTKl0GFUj7fOx75VXsvtddxUc677uOta/970JR1Q90v6zMVwS89HS0tLj7nOHvz5ixW9m8wiq8ky4vwHu7u8Z4X3HAqvdvcfM5o82YHfvBDoB5s6d6/Pnj/pbJKKrq4tqja0SUjsfpdotTJsGr73GNr99KZPan40iKjkfUZZ6fgJ8leBA7OZRfO95wHFm9gmC00DfBVwFTDWz8e7+DjAT3bhdat1hh8Hviqx+9vXpylupOlFaNrzu7ve6+2p3f23wMdKb3P3r7j7T3bPAp4H/cvdWYAlwYrjbQuCOsQYvUlGD7RYKJf0FC+haskRJX6pSlIp/iZldDtzO0H78ozmzJ98FwGIz+zbwOMG/KERqy447Qn9/4bHBdgtdXUlGJBJZlMT/kfBr/hKlM4ord929C+gKnz9PcPWvSO1ZuhQOPrjw2FlnwdVXJxuPyBhEadLWkkQgIlVP7RakTkRZ4xdJt1LtFq66Su0WpOaMpWWDSDqo3YLUKVX8IoVceaXaLUjditKrp9HMLjKzfw+39wkvzhKpeblcjmw2i5kxbtw4JpgFCf288wq/wR2OOy7ZIEXKLErFfwPBaZyHhNurgG/HFpFIQnK5HG1tbfT19QHw64EBiraJ7e5Wjx2pG1ES/17u/h3gvwHcvZ+gbYNITWtvb6e/v59dCc5PPrLAPq8B2UwG5sxJNjiRGEU5uLvJzCYT/G5gZnuRdyGXSK1asWIFpWr4ZuAFwFasSCgikWRESfz/G7gPmGVmOYIePKfGGZRI7B5+mIEiSzevAO/O225W2wWpM1Eu4PqNmT0GHEywxHOOu78ae2QicSlxNs50YE3e9g477EBHR0fsIYkkqegav5l9aPBB0JL5JeBFoDl8TaS23HRTyaQ/rqFhSNKfPn06N9xwA62trfHHJpKgUhX/d0uMjapXj0jFlTrnvr8fJk8eVc9xkVpWNPGrR4/UhXPPhe99r/DYEUeog6akUpQ7cE0CvgQcRlDpPwhc5+5vxRybyNip3YJIUVHO478J+FvgauCH4fOfxhmUyHY59NDiSf+CC9RuQVIvyumc+7n7B/K2l5jZ03EFJDJm/f3BDVKK0ZW3IkC0iv8xM9ty5wkz+wjQHV9IImNgVjzp53JK+iJ5olT8c4CHzGzw8sVm4E9mtgxwd/9gbNGJjOSFF0rf11YJX2QbURL/x2OPQmQsSq3TP/ooHHRQcrGI1JAoV+72mdkuwKz8/bfjZusi2+fhh4MDuMWoyhcpKcrpnN8i6M3zHGzpaaULuKQySlX5q1bB7rsnF4tIjYqy1HMyQWvmoq3KRWJ3002wcGHxcVX5IpFFSfxPAVOB1fGGIlJEhHYLIhJdlNM5LwEeN7Nfmdmdg4+4AxPhvPOKJ/0jjgiqfCV9kVGLUvEvAi4DlgED8YYjgtotiMQsSsXf7+4/cPcl7v7A4CP2yCSd1G5BJHZRKv4HzewS4E7ybrmo0zmlrNRuQSQxURL/geHXg/Ne0+mcUj6lKvhcDj772eRiEUmBKBdwqS+/xGPlSpg1q/i4qnyRWESp+DGzYwjaMU8afM3d/zWuoCQF1G5BpGJGPLhrZtcB/wicTXCz9ZMI7sErMnpLlpRO+u5K+iIxi3JWz6Hu/k/AWnf/JnAIsG+8YUmty+VyZLNZGhoayGaz5HK5IOEvKHJoaNUqLe2IJCTKUs/G8Gu/me0OvAbMiC8kqXW5XI62tjb6+/sBOKavj9ZTTin+BiV8kURFSfx3m9lU4HLgMYIzen4cZ1BS29rb27ck/VIpfTLQlMnQm0RQIrLFiEs97v4td1/n7rcRrO2/z90vij80qVUrVqzgRoon/WcJDha9Fe4rIsmKcnD3JDPbKdz8GnCDmR1Y6j3h+yaZ2aNm9qSZ/cHMvhm+vqeZLTWzZ83sZjObsH3/CVJV3Blwp1gfTQP2ydtuLnX3LBGJRZSDuxe5+5tmdhhwFPAT4LoI73sbWODus4EDgI+H9+69DPieu+8NrAVOG1PkUn0yGeYXOXh7vRkTJwz9G9/Y2EhHR0cSkYlIniiJf3P49Rig093vAUas0j2wPtzcIXwMXvF7a/j6IuD40QQsVWjDhuCMnSLLNtlMhok//SnXX389mUwGMyOTydDZ2Ulra2vCwYqI+QhnVJjZ3cAq4GjgQwRn+TwaVvIjvXcc0APsDVxDcID4kbDax8xmAfe6+34F3tsGtAE0NTXNWbx48Sj+s5Kzfv16pkyZUukwKmZ+S/ELu//81a/y4nHHJRhNdUn7z8Zwmo+hkpiPlpaWHnefO/z1KIm/keCG68vc/RkzmwHs7+6/jvrh4VlBPwcuAm6MkvjzzZ0717u7u6N+XKK6urqYP39+pcNIXm8v7Lln8XGdopnen40iNB9DJTEfZlYw8Uc5q6ff3W9392fC7ZdGk/TD96wDlhBc/DXVzAZPI51J8K8JqSVmRZP+49//vpK+SJWLssY/Jma2W1jpY2aTCZaKlhP8ATgx3G0hcEdcMUiZdXWN2G7h9dkjrgCKSIVFatI2RjOAReE6fwNwi7vfbWZPA4vN7NvA4wRnCUm1K5Xw+/pAp2WK1IzYEr+7/56tvfzzX38e+HBcnytl9qMfwZlnFh/Xso5IzYmz4pdaV6rK37ABGhuTi0VEyia2NX6pYaeeWjzp77VXUOUr6YvULFX8spV78RudAwwM6EbnInVAFb8EstniSf8LXwj+KCjpi9QFVfxpt2EDlLp6UAdvReqOKv40Myue9K+9VklfpE6p4k8jtVsQSTVV/GlTot0CDzygpC+SAkr8aRGh3QKHH55YOCJSOUr8dSiXy5HNZjEzxo8fHyT8Yu2T+/pU5YukjNb460wul6OtrY3+/n6+Dly8eXPxnZXwRVJJib/OtLe309/fX/RG54DaLYiknJZ66sw3+vqKJv3ngAYzJX2RlFPFXy/CdgunFhkePKybUftkkdRTxV8PSrRb+C1bk35jYyMdHR1JRSUiVUoVfy0bod2CAePGjYPNm8lkMnR0dNDa2ppcfCJSlZT4a1Wpc/KvvRa++MXSB3hFJLWU+GuN2i2IyHbSGn+NyOVyarcgImWhir8G/PLii2ltby++gxK+iIyCEn+1M+MTRYbm7bEHv1u5MtFwRKT2aamnWt1xR8kDuAY8/OKLycUjInVDFX81KpHwJwFvh8+bdTGWiIyBKv5qctllRZP+z8aNw9ia9HUxloiMlRJ/NRi8kfmFFxYeHxhg06JFZDIZzIxMJkNnZ6cuxhKRMVHir7TPfKZouwUuvXTLH4XW1lZ6e3sZGBigt7dXSV9Exkxr/JXy1lsweXLxcZ2iKSIxUcVfCXvuWTzp/+IXSvoiEitV/El6+WWYMaP4uBK+iCRAFX9SzIon/SeeUNIXkcQo8cftySdLd9J0h9mzk4tHRFJPSz1xKpXwX3oJ/uZvkotFRCSkij8OpdotZLNBla+kLyIVooq/3EpV+Rs3wqRJycUiIlKAKv5y+c53iif9T386qPKV9EWkCsRW8ZvZLOAmoAlwoNPdrzKzacDNQBboBU5297VxxRG7wXYLxQwMlB4XEUlYnBX/O8B57v4B4GDgTDP7AHAhcL+77wPcH27XlFwuRzab5T/NmL9gQeGd8totiIhUk9gqfnd/CXgpfP6mmS0H9gA+CcwPd1sEdAEXxBVHueVyOc48/XTWbdxYfCedky8iVSyRNX4zywIHAkuBpvCPAsDLBEtBNeP/fPWrxZO+2i2ISA0wjzlRmdkU4AGgw91vN7N17j41b3ytu+9S4H1tQBtAU1PTnMWLF8ca50gaNm3ikJNOYoc33ig4/t0rrmDOnDkJR1V91q9fz5QpUyodRlXQXAyl+RgqifloaWnpcfe52wy4e2wPYAfgV8C5ea/9CZgRPp8B/Gmk7zNnzhyvqOuvdw9q+W0ei8491wHPZDKVjbFKLFmypNIhVA3NxVCaj6GSmA+g2wvk1NiWeszMgJ8Ay939yryhO4GF4fOFwB1xxbDd1q0LDs5+4QvbDH2e4L63r+y+OxMmTNDdsESkZsS5xj8P+BywwMyeCB+fAC4FjjazZ4Cjwu3qc8klsMs2K1CsIbjv7Y15r+200066MYqI1Iw4z+r5LUFRXMiRcX3udnvxRdhjj4JDxwL3FHh9zZo1sYYkIlJOunI331lnFU76s2fDO+/wVCZT8G3Nzc0xByYiUj5K/MBdl18erOVfc822gw89FPTLHzeOjo4OGhsbhww3NDRofV9Eakq6m7S5s3LOHP7h8ce3GVp54IHM7OkZcuXt4Dp+e3s7K1asoLm5mUwmwwknnJBYyCIi2yu9Ff8jj0BDAzMLJP33A4etWVOw3UJrayu9vb0MDAzQ29vLtGnTEghWRKR80pf4N2+GAw6AQw7ZZugagqPRfwRWrFiRcGAiIsmo28Q/2EitoaGBbDZLLpeDe+6B8eOD2yEOswdwVt62DtiKSL2qyzX+XC5HW1sb/f39ALzc18ffn3JKwX2fOOkk5t1zz5Z9ARobG3XAVkTqVl1W/O3t7VsS+anAW0DBlfi1azngllvo7Owkk8lgZmQyGTo7O3VBlojUrbqs+AfX518Fphfa4frr4fOf37LZ2tqqRC8iqVGXib+5uZn39/Vtk/TXNTQwdcMG3QJRRFKtLpd6Ojo6eHviRAbyXvvUxIncc9NNSvoiknp1WfEPLtscf/75bHz5ZZ5rbuZbF1+s5RwREeo08YPW7UVEiqnLpR4RESlOiV9EJGWU+EVEUkaJX0QkZZT4RURSRolfRCRllPhFRFLG3L3SMYzIzF4B+iodRxG7ErQFkoDmYyvNxVCaj6GSmI+Mu+82/MWaSPzVzMy63X1upeOoFpqPrTQXQ2k+hqrkfGipR0QkZZT4RURSRol/+3VWOoAqo/nYSnMxlOZjqIrNh9b4RURSRhW/iEjKKPGLiKSMEn9EZjbLzJaY2dNm9gczOyd8fZqZ/cbMngm/7lLpWJNgZpPM7FEzezKcj2+Gr+9pZkvN7Fkzu9nMJlQ61qSY2Tgze9zM7g63UzsXAGbWa2bLzOwJM+sOX0vr78tUM7vVzP5oZsvN7JBKzoUSf3TvAOe5+weAg4EzzewDwIXA/e6+D3B/uJ0GbwML3H02cADwcTM7GLgM+J677w2sBU6rXIiJOwdYnred5rkY1OLuB+Sdr57W35ergPvc/X3AbIKfk4rNhRJ/RO7+krs/Fj5/k+B/3B7AJ4FF4W6LgOMrEmDCPLA+3NwhfDiwALg1fD0182FmM4FjgB+H20ZK52IEqft9MbOdgcOBnwC4+yZ3X0cF50KJfwzMLAscCCwFmtz9pXDoZaCpUnElLVzaeAJYDfwGeA5Y5+7vhLusJPjjmAbfB/4FGAi3p5PeuRjkwK/NrMfM2sLX0vj7sifwCnBDuBT4YzPbkQrOhRL/KJnZFOA24Cvu/kb+mAfnxqbm/Fh33+zuBwAzgQ8D76tsRJVhZscCq929p9KxVJnD3P1DwN8TLI0enj+Yot+X8cCHgGvd/UBgA8OWdZKeCyX+UTCzHQiSfs7dbw9f/quZzQjHZxBUv6kS/rN1CXAIMNXMxodDM4FVlYorQfOA48ysF1hMsMRzFemciy3cfVX4dTXwc4LiII2/LyuBle6+NNy+leAPQcXmQok/onDN9ifAcne/Mm/oTmBh+HwhcEfSsVWCme1mZlPD55OBowmOeywBTgx3S8V8uPvX3X2mu2eBTwP/5e6tpHAuBpnZjma20+Bz4KPAU6Tw98XdXwZeMLP3hi8dCTxNBedCV+5GZGaHAQ8Cy9i6jvs/Cdb5bwGaCVpHn+zuayoSZILM7IMEB6TGERQQt7j7v5rZewiq3mnA48Ap7v525SJNlpnNB85392PTPBfhf/vPw83xwH+4e4eZTSedvy8HEBz4nwA8D3ye8PeGCsyFEr+ISMpoqUdEJGWU+EVEUkaJX0QkZZT4RURSRolfRCRllPilpoRdDr807LX7zGzdYFfMEu/9/uDVo2b2d2FX0SfC6xDiivcbZnb+CPvcaGYnltpn2P5ZM3sqfL6/md24nWFKyijxS62ZCnxp2GuXA58r9abw/PGD3f3/hi+1ApeEnSM35u03vuA3qFLuvgyYaWbNlY5FaocSv9SaS4G9wkr9cgB3vx94c4T3fQq4D8DM/gdwMvAtM8uZ2Xwze9DM7gSeDu81cEPYS/5xM2sJ33eqmf0i7J3ea2Znmdm54T6PmNm0UgGY2elm9v/CexjcZmaNecNHmVm3mf057P0z2ATv8vA9vzezM4p867sIrhgWiUSJX2rNhcBzYaX+tVG8bx7QA+DuPya4XP5rYWsFCHqnnOPu+wJnBrv5/sBngEVmNincbz/gBOAgoAPoDxtvPQz80wgx3O7uB4X3MFjO0P78WYJeNscA14WfdxrwursfFH7e6Wa2Z4Hv2w38XbRpEAkupRZJgxkErXGLedTd/xI+Pwy4GsDd/2hmfcC+4diS8H4Mb5rZ6wTVNgStPD44Qgz7mdm3CZarpgC/yhu7xd0HgGfM7HmCTqcfBT6Yt/6/M7AP8Odh33c1sPsIny2yhRK/pMVGYFKJ8Q0Rv09+r52BvO0BRv59uhE43t2fNLNTgfl5Y8N7pzhgwNnunv8HYvB+EPkmEfz3iUSipR6pNW8CO43hfcuBvSPu+yDBwV/MbF+CJlp/GsNnDrcT8FLY3rt12NhJZtZgZnsB7wk/71fAP4f7Y2b7hp0uh9uXoPOlSCRK/FJT3P014Hdm9tTgwV0zexD4GXCkma00s48VeOs9DK2wS/kR0GBmy4CbgVPL1FXzIoJurr8D/jhsbAXwKHAv8EV3f4ugm+PTwGPh6Zv/RuF/VbQQ/PeJRKLunJIaZvZb4NjwxjF1wcwmAg8Q3O3qnZH2FwElfkkRM/sIsNHdf1/pWMrFzPYB9nD3rkrHIrVDiV9EJGW0xi8ikjJK/CIiKaPELyKSMkr8IiIpo8QvIpIy/x9ksFXUY2hJKgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There may be a cleaner way to do this, but it works. It gives a nice plot\n",
    "# and one can use the regr.predict() method in later cells to convert the labels\n",
    "\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Add column to dataframe with sample number of peak and\n",
    "# then slice dataframe to keep only single pulse waveforms\n",
    "waveforms = df.to_numpy()                              # Convert all labels+waveforms to numpy arrays\n",
    "waveforms = np.delete(waveforms, range(5), axis=1)     # Remove labels\n",
    "locmax = np.argmin(waveforms, axis=1)                  # Find index of sample at peak\n",
    "dflocmax = pd.DataFrame(locmax, columns=['maxsample']) # Create new dataframe with just one column containing peak location\n",
    "df2 = pd.concat([df, dflocmax], axis=1)                # Create new dateframe with the new column added\n",
    "dfA1_not_A2 = df2[(df2.A1>600.0) & (df2.A2==0)]        # Slice the dataframe to contain only waveforms with single, large pulses\n",
    "\n",
    "# Do linear regression fit\n",
    "N = len(dfA1_not_A2)\n",
    "y = dfA1_not_A2['maxsample'].values.reshape(N,1)\n",
    "x = dfA1_not_A2['t1'].values.reshape(N,1)\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(x, y)\n",
    "m = regr.coef_\n",
    "b = regr.intercept_\n",
    "\n",
    "# Plot results\n",
    "print('Fit Parameters: slope=%f  intercept=%f' % (m,b))\n",
    "plt.scatter(x, y,  color='black')\n",
    "plt.plot(x, regr.predict(x), color='red', linewidth=3)\n",
    "plt.ylabel('sample number')\n",
    "plt.xlabel('t1 (from label)')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows a y-intercept of significantly less than 1 sample and a slope very close to 1. It is probably safe to assume the units of time used for the labels are sample numbers where t=0.0 corresponds to the first sample.\n",
    "\n",
    "\n",
    "## Prepare training set\n",
    "\n",
    "Each set of features in the training set will be a list of 128 samples. In a final application, it would be nice to feed a continuous stream of samples to the model and have it \"emit\" a time/amplitude whenever it encounters a pulse. This makes the labels the tricky part. This first thing I'll try is making labels that specify how far back in time the pulse occured relative to the current sample. I'll make these labels such that 10 samples after the time given by the label from the CSV file are when the pulse should be emitted. This allows the network to accumulate data on the downward pulse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples: 988\n",
      "rnn_waveforms shape: (1000, 128, 1)  rnn_labels shape: (1000, 128, 4)\n",
      "shape x: (1, 12, 128, 1)   shape y: (1, 128, 4)\n",
      "[[[[ 0.]\n",
      "   [ 5.]\n",
      "   [ 0.]\n",
      "   ...\n",
      "   [-2.]\n",
      "   [-1.]\n",
      "   [12.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [-2.]\n",
      "   [ 6.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [-4.]\n",
      "   [ 4.]]\n",
      "\n",
      "  [[-1.]\n",
      "   [ 0.]\n",
      "   [ 4.]\n",
      "   ...\n",
      "   [ 0.]\n",
      "   [-1.]\n",
      "   [ 6.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 0.]\n",
      "   [-3.]\n",
      "   [ 6.]\n",
      "   ...\n",
      "   [-2.]\n",
      "   [ 0.]\n",
      "   [ 4.]]\n",
      "\n",
      "  [[ 4.]\n",
      "   [-4.]\n",
      "   [12.]\n",
      "   ...\n",
      "   [ 5.]\n",
      "   [ 5.]\n",
      "   [-4.]]\n",
      "\n",
      "  [[ 0.]\n",
      "   [ 1.]\n",
      "   [-1.]\n",
      "   ...\n",
      "   [ 2.]\n",
      "   [ 9.]\n",
      "   [-1.]]]] => [[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "avg_pulse_width = 12\n",
    "\n",
    "# Add a dimension to waveforms since every sample will be an input feature\n",
    "rnn_waveforms = waveforms.reshape((waveforms.shape[0],waveforms.shape[1],1))\n",
    "\n",
    "# Create numpy array for labels, initialized to all zeros\n",
    "rnn_labels = np.zeros(shape=(rnn_waveforms.shape[0],rnn_waveforms.shape[1],4))\n",
    "\n",
    "generator = TimeseriesGenerator(rnn_waveforms, rnn_labels, length=avg_pulse_width, batch_size=1)\n",
    "print('Samples: %d' % len(generator))\n",
    "print('rnn_waveforms shape: %s  rnn_labels shape: %s' % (str(rnn_waveforms.shape), str(rnn_labels.shape)))        \n",
    "\n",
    "for i in range(1):\n",
    "    x, y = generator[i]\n",
    "    print('shape x: %s   shape y: %s' % (str(x.shape), str(y.shape)))\n",
    "    print('%s => %s' % (x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_waveforms shape: (190071, 128, 1)  rnn_labels shape: (190071, 128, 4)\n"
     ]
    }
   ],
   "source": [
    "# Make labels for each time step of each waveform\n",
    "# Format will be:\n",
    "#\n",
    "#   [[sample0], [sample1], [sample2], ...]    features\n",
    "#   [[ped,A,t], [ped,A,t], [ped,A,t], ...]    labels\n",
    "import math\n",
    "\n",
    "emit_sample_offset = 8  # Number of samples after true time to wait before emitting sample\n",
    "\n",
    "# Add a dimension to waveforms since every sample will be an input feature\n",
    "rnn_waveforms = waveforms.reshape((waveforms.shape[0],waveforms.shape[1],1))\n",
    "\n",
    "# Create numpy array for labels, initialized to all zeros\n",
    "rnn_labels = np.zeros(shape=(rnn_waveforms.shape[0],rnn_waveforms.shape[1],4))\n",
    "\n",
    "# Create numpy array of just labels from CSV file\n",
    "labels = df.to_numpy()                                        # Convert all labels+waveforms to numpy arrays\n",
    "labels = np.delete(labels, range(5,labels.shape[1]), axis=1)  # Remove samples\n",
    "\n",
    "# Loop over waveforms, updating rnn_labels for those samples where we want pulse parameters emitted\n",
    "for i in range(len(rnn_waveforms)):\n",
    "    # t1\n",
    "    if labels[i,3]>=0 :\n",
    "        isample = int(math.floor(labels[i,3]) + emit_sample_offset)\n",
    "        delta_t = float(isample) - labels[i,3]\n",
    "        rnn_labels[i,isample] = [1, labels[i,0], labels[i,1], delta_t]  # ([ped, A1, t1])\n",
    "    # t2\n",
    "    if labels[i,4]>=0 :\n",
    "        isample = int(math.floor(labels[i,4]) + emit_sample_offset)\n",
    "        delta_t = float(isample) - labels[i,4]\n",
    "        rnn_labels[i,isample] = [1, labels[i,0], labels[i,2], delta_t]  # ([ped, A2, t2])\n",
    "\n",
    "print('rnn_waveforms shape: %s  rnn_labels shape: %s' % (str(rnn_waveforms.shape), str(rnn_labels.shape)))        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, None, 32)          4352      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 32)          8320      \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, None, 4)           132       \n",
      "=================================================================\n",
      "Total params: 21,124\n",
      "Trainable params: 21,124\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, TimeDistributed, Input, Lambda, LSTM\n",
    "\n",
    "# Model will have single input: the sample amplitude\n",
    "# It will have two outputs: time and amplitude of pulse\n",
    "def DefineModel():\n",
    "    model = Sequential()\n",
    "    model.add( LSTM(units=32, return_sequences=True, input_shape=(None,1)) )  #  None -> undefined number of time steps\n",
    "    model.add( LSTM(units=32, return_sequences=True) )\n",
    "    model.add( LSTM(units=32, return_sequences=True) )\n",
    "    model.add( TimeDistributed(Dense(units=4)) )\n",
    "    return model\n",
    "\n",
    "def CustomLoss(y_true, y_pred):\n",
    "    print('y_pred shape: %s   y_true shape: %s' % (str(y_pred), str(y_true)))\n",
    "    \n",
    "\n",
    "model = DefineModel()\n",
    "model.compile(optimizer='adam', loss=CustomLoss, metrics=['mse', 'mae'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_waveforms shape: (190071, 128, 1)  rnn_labels shape: (190071, 128, 4)\n",
      "y_pred shape: Tensor(\"sequential/time_distributed/Reshape_1:0\", shape=(None, 128, 4), dtype=float32)   y_true shape: Tensor(\"IteratorGetNext:1\", shape=(None, 128, 4), dtype=float32)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:151 __call__\n        losses, sample_weight, reduction=self._get_reduction())\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:106 compute_weighted_loss\n        losses = ops.convert_to_tensor_v2(losses)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1382 convert_to_tensor_v2\n        as_ref=False)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1499 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:338 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        allow_broadcast=True)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:282 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:444 make_tensor_proto\n        raise ValueError(\"None values not supported.\")\n\n    ValueError: None values not supported.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8e57976edc45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    696\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 697\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3073\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3075\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3076\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3077\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:749 train_step\n        y, y_pred, sample_weight, regularization_losses=self.losses)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/losses.py:151 __call__\n        losses, sample_weight, reduction=self._get_reduction())\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:106 compute_weighted_loss\n        losses = ops.convert_to_tensor_v2(losses)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1382 convert_to_tensor_v2\n        as_ref=False)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py:1499 convert_to_tensor\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:338 _constant_tensor_conversion_function\n        return constant(v, dtype=dtype, name=name)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:264 constant\n        allow_broadcast=True)\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py:282 _constant_impl\n        allow_broadcast=allow_broadcast))\n    /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py:444 make_tensor_proto\n        raise ValueError(\"None values not supported.\")\n\n    ValueError: None values not supported.\n"
     ]
    }
   ],
   "source": [
    "print('rnn_waveforms shape: %s  rnn_labels shape: %s' % (str(rnn_waveforms.shape), str(rnn_labels.shape)))        \n",
    "\n",
    "BATCH_SIZE=32\n",
    "EPOCHS=1\n",
    "\n",
    "history = model.fit(\n",
    "    x=rnn_waveforms,\n",
    "    y=rnn_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_save_dir=\"2020.10.25-12:42\"\n",
      "INFO:tensorflow:Assets written to: RNN_models/2020.10.25-12:42/assets\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "import time \n",
    "model_save_dir = time.strftime('%Y.%m.%d-%H:%M')\n",
    "print('model_save_dir=\"%s\"' % model_save_dir)\n",
    "model.save('RNN_models/'+model_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "\n",
    "Here we test the model by giving it a wavform and seeing the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.13243, 263.75, 0.0, 38.0609, -1.0]\n",
      "[[[-2.43019909e-02  3.00599813e-01 -2.49379687e-02]\n",
      "  [-1.15752909e-02 -1.36694193e-01  2.88562197e-03]\n",
      "  [-2.79591791e-03 -1.36397123e-01  3.94996107e-02]\n",
      "  [-5.75227290e-03  1.92675591e-01  6.82029650e-02]\n",
      "  [-8.53197090e-03  2.17434406e-01  6.11457229e-02]\n",
      "  [-1.00968182e-02  1.34024620e-01  4.80487123e-02]\n",
      "  [-9.85159539e-03  6.03497028e-02  1.84858702e-02]\n",
      "  [-7.88105279e-03 -8.53276253e-03 -3.38472752e-03]\n",
      "  [-3.77660803e-03 -1.94060802e-02 -1.56790689e-02]\n",
      "  [ 1.02602132e-03 -1.66916847e-03 -1.23903928e-02]\n",
      "  [ 5.06734475e-04 -2.51238346e-02 -3.40071972e-03]\n",
      "  [-3.86456028e-04  1.09283924e-02  1.81947183e-03]\n",
      "  [-1.51976012e-03  2.52463818e-02  3.36585008e-03]\n",
      "  [-2.94969976e-03  3.71434689e-02  4.04399540e-03]\n",
      "  [-3.14571336e-03  2.02960968e-02  1.03704445e-03]\n",
      "  [-4.83752042e-03  3.83076668e-02  2.13318411e-03]\n",
      "  [-3.81806493e-03 -2.88009644e-03 -4.91969381e-03]\n",
      "  [-4.07870673e-03  2.24642754e-02 -6.26969337e-03]\n",
      "  [-2.55214982e-03 -2.83045769e-02 -1.50738414e-02]\n",
      "  [-4.08781320e-03  5.82134724e-02 -5.86792361e-03]\n",
      "  [-3.75323370e-03  1.43947601e-02 -8.21725372e-03]\n",
      "  [-4.33208980e-03  3.76408100e-02 -6.92295469e-03]\n",
      "  [-2.59225257e-03 -3.46961021e-02 -1.75296627e-02]\n",
      "  [-3.20192799e-03  4.39107418e-02 -1.08794170e-02]\n",
      "  [-6.95360824e-04 -4.82034683e-02 -2.15871949e-02]\n",
      "  [-1.46578252e-03  2.84786224e-02 -1.12915793e-02]\n",
      "  [ 3.12855281e-03 -1.53131485e-02 -1.69637930e-02]\n",
      "  [-1.10789202e-03  2.96785831e-02 -2.60400074e-03]\n",
      "  [-1.40254572e-03  1.88219547e-02 -2.32163584e-03]\n",
      "  [-4.21736389e-03  4.93032932e-02  2.22017337e-03]\n",
      "  [-2.51504965e-03 -9.36055183e-03 -4.26687906e-03]\n",
      "  [-2.70732492e-03  2.21602917e-02 -4.42494825e-03]\n",
      "  [ 3.75485606e-03  5.64932823e-03 -1.32409073e-02]\n",
      "  [ 1.53794531e-02  4.04871464e-01  2.48499271e-02]\n",
      "  [ 1.52932834e-02 -2.20427752e-01  5.26021495e-02]\n",
      "  [ 3.70980874e-02  6.63773775e-01  1.02485806e-01]\n",
      "  [ 6.59600943e-02  2.10067749e-01 -9.72550884e-02]\n",
      "  [ 3.10650785e-02  6.73685074e-02 -1.90481514e-01]\n",
      "  [-3.98962311e-02 -2.21986055e-01 -1.60347149e-01]\n",
      "  [-1.96725782e-02 -3.79250050e-01 -1.06876411e-01]\n",
      "  [ 1.61025133e-02 -5.57149172e-01 -6.45065755e-02]\n",
      "  [ 3.01933270e-02 -5.98984003e-01 -3.89714465e-02]\n",
      "  [ 3.52521017e-02 -2.33027935e-02 -3.84237766e-02]\n",
      "  [ 4.86091375e-02  4.31481123e-01  5.58561459e-03]\n",
      "  [ 7.49666616e-02 -3.79711628e-01  5.62892482e-02]\n",
      "  [-6.16167933e-02 -2.75177407e+00 -6.44222736e-01]\n",
      "  [ 1.27875209e-01  2.57747746e+01  6.21694565e-01]\n",
      "  [ 4.88173187e-01  1.24703270e+02  5.59145737e+00]\n",
      "  [ 2.60550827e-01  4.89202461e+01  2.75786304e+00]\n",
      "  [-1.12927243e-01  1.97531939e+00 -1.66064836e-02]\n",
      "  [ 7.75126889e-02  8.34467411e-01  2.44703397e-01]\n",
      "  [-1.55534120e-02  1.24936032e+00  2.99093217e-01]\n",
      "  [-1.82872936e-02  6.35254622e-01  2.12765098e-01]\n",
      "  [-3.52446735e-02  4.48900938e-01  1.55065432e-01]\n",
      "  [-4.63725477e-02  4.57298756e-01  1.07590988e-01]\n",
      "  [-4.06141728e-02  4.19695377e-01  4.35046479e-02]\n",
      "  [-2.58663930e-02 -6.44469261e-03 -4.80131209e-02]\n",
      "  [-6.20145723e-03 -6.87394142e-02 -1.06093228e-01]\n",
      "  [ 9.21130367e-03  1.71139240e-02 -1.31127745e-01]\n",
      "  [ 1.53961349e-02 -2.02200413e-02 -1.46175981e-01]\n",
      "  [ 1.63306650e-02 -1.02839231e-01 -1.44406319e-01]\n",
      "  [ 1.67690720e-02 -2.72634029e-02 -1.23395562e-01]\n",
      "  [ 1.80897918e-02  1.70545578e-02 -1.00780718e-01]\n",
      "  [ 1.85861941e-02 -1.01392508e-01 -8.78170580e-02]\n",
      "  [ 2.12064739e-02  5.77747822e-02 -5.32462746e-02]\n",
      "  [ 2.24157404e-02  1.45294666e-02 -2.70877890e-02]\n",
      "  [ 2.36911457e-02 -4.09836769e-02 -5.13251219e-03]\n",
      "  [ 2.56472919e-02  2.89170742e-02  1.71958152e-02]\n",
      "  [ 2.74120253e-02  9.39681530e-02  2.70104725e-02]\n",
      "  [ 2.96831597e-02  1.14498615e-01  2.27989312e-02]\n",
      "  [ 3.16357613e-02  1.10139132e-01  1.14866644e-02]\n",
      "  [ 3.18875536e-02  3.21724415e-01  9.21836123e-03]\n",
      "  [ 3.61744016e-02  1.75749302e-01 -2.50832047e-02]\n",
      "  [ 3.48914266e-02 -2.81870365e-02 -5.38895503e-02]\n",
      "  [ 3.26233283e-02  2.44855881e-03 -6.25013337e-02]\n",
      "  [ 2.92798560e-02 -3.25667858e-02 -6.61973059e-02]\n",
      "  [ 2.26620492e-02 -7.63225555e-02 -6.25542104e-02]\n",
      "  [ 1.54117998e-02 -5.53286076e-02 -4.94441167e-02]\n",
      "  [ 1.15686860e-02 -4.36916351e-02 -4.10947204e-02]\n",
      "  [ 1.02404747e-02 -3.20277214e-02 -3.27984393e-02]\n",
      "  [ 4.29898687e-03 -2.60870457e-02 -1.97663661e-02]\n",
      "  [ 9.90543514e-04  1.53958797e-02 -1.20312544e-02]\n",
      "  [-3.90112400e-04  1.21872425e-02 -9.48643684e-03]\n",
      "  [-3.12404335e-03  3.98104191e-02 -5.26572671e-03]\n",
      "  [-3.64831463e-03  2.13162899e-02 -6.58163056e-03]\n",
      "  [-7.75383785e-04 -2.16264725e-02 -1.63298193e-02]\n",
      "  [ 2.95488723e-03  2.21176147e-02 -1.37265949e-02]\n",
      "  [ 4.09271568e-04  2.26635933e-02 -4.00689617e-03]\n",
      "  [-2.16423161e-03  5.74045181e-02  2.62848102e-04]\n",
      "  [-1.40691549e-03  2.02567577e-02 -1.94302434e-03]\n",
      "  [-1.67443417e-03  3.73866558e-02 -1.89446658e-03]\n",
      "  [-1.19433738e-03  2.71148682e-02 -3.89424898e-03]\n",
      "  [-1.30448490e-03  3.77676487e-02 -3.93268699e-03]\n",
      "  [-8.79682600e-04  2.83865929e-02 -5.80749474e-03]\n",
      "  [-6.50709495e-04  3.15968990e-02 -6.44865958e-03]\n",
      "  [-1.93980895e-03  5.64143658e-02 -4.18225024e-03]\n",
      "  [-2.36509740e-03  4.40773964e-02 -5.44211548e-03]\n",
      "  [ 1.32667087e-03 -1.10747814e-02 -1.61783118e-02]\n",
      "  [ 2.34818645e-03  3.14819813e-02 -9.28494707e-03]\n",
      "  [ 1.38901360e-03  2.53975391e-02 -3.58695025e-03]\n",
      "  [ 9.50766727e-04  3.25090885e-02 -4.51729633e-04]\n",
      "  [ 5.67527488e-04  3.42917442e-02  8.30754638e-04]\n",
      "  [-3.91470268e-04  4.76012230e-02  1.67397875e-03]\n",
      "  [ 1.74685381e-03  1.70574188e-02 -3.26497899e-03]\n",
      "  [-2.29173154e-03  7.09033012e-02  3.04714125e-03]\n",
      "  [-1.93433277e-03  2.87508965e-02 -7.66118057e-04]\n",
      "  [-5.21689467e-03  6.00790977e-02  2.30549648e-03]\n",
      "  [-5.45038283e-03  2.42958069e-02 -2.16885097e-03]\n",
      "  [-5.63073903e-04 -3.54955196e-02 -1.77948885e-02]\n",
      "  [-5.22581860e-04  2.02000141e-02 -7.46746827e-03]\n",
      "  [-1.10130943e-03  1.54383183e-02 -3.75761231e-03]\n",
      "  [-2.49038264e-03  3.75993252e-02  7.53197819e-05]\n",
      "  [-2.20414810e-03  2.12104321e-02 -1.18187582e-03]\n",
      "  [-2.50967033e-03  3.31001282e-02 -1.49049656e-03]\n",
      "  [-1.79029256e-03  1.72612667e-02 -4.56207199e-03]\n",
      "  [-1.78097934e-03  3.06768417e-02 -4.88581974e-03]\n",
      "  [-2.38427334e-03  4.21357155e-02 -4.55646496e-03]\n",
      "  [-5.25514036e-03  5.78265190e-02  2.55565438e-03]\n",
      "  [-2.34194659e-03 -1.87010765e-02 -1.12180756e-02]\n",
      "  [-3.03022936e-03  2.91709900e-02 -8.15063249e-03]\n",
      "  [-3.59047018e-03  3.51428986e-02 -7.37794628e-03]\n",
      "  [-3.75392102e-03  3.24935913e-02 -7.26744812e-03]\n",
      "  [-1.41141936e-03 -2.50072479e-02 -1.62368193e-02]\n",
      "  [-2.04130448e-03  3.47750187e-02 -9.03857965e-03]\n",
      "  [-1.20245852e-03  3.93891335e-03 -1.08746132e-02]\n",
      "  [-7.28631392e-04  1.52814388e-02 -9.38926172e-03]\n",
      "  [-6.43055886e-04  1.91130638e-02 -7.92224891e-03]\n",
      "  [-4.14907373e-03  6.61973953e-02  4.06882912e-03]]]\n"
     ]
    }
   ],
   "source": [
    "def TestWaveform(mydf, irow):\n",
    "    row = mydf.iloc[irow].tolist()\n",
    "    \n",
    "    waveform = np.reshape(row[5:],(1,128,1))\n",
    "    label    = row[:5]\n",
    "    \n",
    "    model.reset_states()\n",
    "    y_pred = model.predict(waveform)\n",
    "    print(label)\n",
    "    print(y_pred)\n",
    "\n",
    "TestWaveform(df, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, HTML, display\n",
    "import png\n",
    "import os\n",
    "\n",
    "# Generate one PNG image file for the specified entry and dataframe.\n",
    "# The drawlines option can set whether to draw lines between points.\n",
    "# The prefix value will be prepended on the outpout filenames.\n",
    "def MakeImage(irow, drawlines=False, mydf=df, prefix='', dirname='.'):\n",
    "    row = mydf.iloc[irow][5:].tolist()\n",
    "    \n",
    "    width  = 128\n",
    "    height = 512+100\n",
    "    img = []\n",
    "    for y in range(height):\n",
    "        r = [255]*width\n",
    "        img.append(r)\n",
    "\n",
    "    for icol in range(width):\n",
    "        yval = (100-int(row[icol]))  # For positive pulses: height - (100-int(row[icol]))\n",
    "        yval = min(height-1, max(0, yval))\n",
    "        img[yval][icol] = 0\n",
    "        \n",
    "        # Optionally draw lines between the dots\n",
    "        if drawlines:\n",
    "            if icol>0 :\n",
    "                ymid = (int)((yval + last_yval)/2)\n",
    "                ylo = min(last_yval, ymid)\n",
    "                yhi = max(last_yval, ymid)\n",
    "                for ylin in range(ylo, yhi): img[ylin][icol-1] = 0\n",
    "                ylo = min(ymid, yval)\n",
    "                yhi = max(ymid, yval)\n",
    "                for ylin in range(ylo, yhi): img[ylin][icol-1] = 0\n",
    "            last_yval = yval\n",
    "    fname = prefix+'waveform_%06d.png' % irow\n",
    "    if dirname != '.':\n",
    "        try:\n",
    "            os.makedirs(dirname)\n",
    "        except:\n",
    "            pass  # assume excpetion is because it already exists\n",
    "        fname = os.path.join(dirname, fname)\n",
    "    with open(fname, 'wb') as f:    \n",
    "        w = png.Writer(width, height, greyscale=True)\n",
    "        w.write(f, img)\n",
    "        #print('Wrote file: ' + fname)\n",
    "    return fname"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2020.10.13.tf2.3.1",
   "language": "python",
   "name": "venv_2020.10.13.tf2.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
