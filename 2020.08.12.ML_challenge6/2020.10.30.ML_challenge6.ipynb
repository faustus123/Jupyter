{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Challenge Problem 6 Part 5\n",
    "\n",
    "In this notebook I decided to try straight up calculating the pedestal vsalues by just averaging all samples that lie within a band around zero. This should cut out the majority of any actual pulses or noise. Th thinking is that this could be a pretty accurate estimate that when fed to a model with the waveform itself, would allow the model to focus solely on calculating a correction.\n",
    "\n",
    "The first thing to do (as always) is read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of waveforms: 190071\n"
     ]
    }
   ],
   "source": [
    "# Read the full data file into a dataframe\n",
    "# This file does not have a header so we define the column names here explicitly\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_FILE  = '/home/davidl/work2/2020.08.12.ML_challenge6/Aug_2020_ML_train.csv'\n",
    "\n",
    "# Columns in input file. First 5 are labels\n",
    "names = ['ped', 'A1', 'A2', 't1', 't2']\n",
    "\n",
    "# Next 128 are features (waveform)\n",
    "for i in range(0,128): names.append('s%03d' % i)\n",
    "\n",
    "# Read file and print how many waveforms are found\n",
    "df = pd.read_csv(TRAIN_FILE, names=names)\n",
    "print('Number of waveforms: %d' % len(df.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define non-trainable Model\n",
    "\n",
    "Here I define a model with a single Lambda layer. It calls the CalcPed procedure which calculates the average for all samples within the specified band. Since there are no trainable parameters, I don't need to fit the model. I can simply predict with it and compare the results with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-vczedisu because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "waveform (InputLayer)        [(None, 128, 1)]          0         \n",
      "_________________________________________________________________\n",
      "lambda (Lambda)              (None, 1, 1)              0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, Lambda, Conv1D\n",
    "from tensorflow.keras.optimizers import SGD, Adamax, Adadelta, Adam\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.losses\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NINPUTS = 128\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# CalcPed\n",
    "#-----------------------------------------------------\n",
    "def CalcPed(inputs, vmin=-30.0, vmax=100.0):\n",
    "    \n",
    "    # Calculate mask of values in the inputs that fall between the minimum and maximum\n",
    "    min_mask = vmin*K.ones_like(inputs)\n",
    "    min_mask = K.cast_to_floatx(K.greater(inputs, min_mask))\n",
    "    max_mask = vmax*K.ones_like(inputs)\n",
    "    max_mask = K.cast_to_floatx(K.less(inputs, max_mask))\n",
    "\n",
    "    # Combine upper and lower limit masks into single mask of values to average and apply\n",
    "    mask = min_mask*max_mask\n",
    "    sparse_waveforms = inputs * mask\n",
    "\n",
    "    # Find average of elements not filtered by mask\n",
    "    Nvals = K.sum(mask, axis=1)\n",
    "    Sum = K.sum(sparse_waveforms, axis=1)\n",
    "    \n",
    "    avg = tf.math.divide_no_nan(Sum, Nvals)\n",
    "    ped = K.expand_dims(avg)\n",
    "    \n",
    "    return -ped   # minus sign  is because waveform is sign inverted\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineModel\n",
    "#-----------------------------------------------------\n",
    "# This is used to define the model. It is only called if no model\n",
    "# file is found in the model_checkpoints directory.\n",
    "def DefineModel():\n",
    "    \n",
    "    vmin = -100\n",
    "    vmax = 15\n",
    "\n",
    "    inputs  = Input(shape=(NINPUTS,1), name='waveform')\n",
    "    x = Lambda(CalcPed, arguments={'vmin':vmin, 'vmax':vmax})(inputs)\n",
    "    outputs = Reshape((1,))(x)\n",
    "\n",
    "    model   = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(loss='mse', optimizer=Adam(), metrics=['mae', 'mse'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = DefineModel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Calculation Model\n",
    "\n",
    "Here I use the model to calculate the pedestal and compare it to the labels. I make 2 histograms. The one on the left to show the difference between predicted and truth. The one on the right to show sample values. The one on the right gives me an idea of where to place the cuts on the waveform for samples to include in the average.\n",
    "\n",
    "In the end, I played with the cuts empirically to try and minimize the rms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: -0.269164   rms: 3.469881\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "mydf = df\n",
    "y_labels = mydf.loc[:,['ped']].to_numpy()\n",
    "x_waveform = mydf.iloc[:,5:133].mul(-1)\n",
    "\n",
    "y_pred = model.predict(x_waveform)\n",
    "\n",
    "y_diff = np.squeeze(y_pred - y_labels)\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(20,5))\n",
    "ax[0].hist(y_diff, range=(-20.0,20.0), bins=200)\n",
    "ax[0].grid()\n",
    "ax[0].set_title('Pedestal Prediction Error')\n",
    "ax[0].set_xlabel('ped (model - truth)')\n",
    "\n",
    "x_waveform_sample = np.reshape(x_waveform[:1000].to_numpy(), (128000,))\n",
    "ax[1].hist(x_waveform_sample, range=(-40.0,40.0), bins=81)\n",
    "ax[1].grid()\n",
    "ax[1].set_title('Waveform Sample Values')\n",
    "ax[1].set_xlabel('samples')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate rms and mean\n",
    "mean = np.mean(y_diff)\n",
    "rms = np.sqrt(np.mean(y_diff**2))\n",
    "print('mean: %f   rms: %f' % (mean,rms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Number of pulses\n",
    "\n",
    "One of the criteria of the problem was to acurrately predict the number of pulses in the waveform. Here I want to train a model that does just that. The first thing I will need though is a column in the dataframe that has this value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number 0, 1, and 2 pulse waveforms: [126000  63000   1071]\n"
     ]
    }
   ],
   "source": [
    "vA1 = df['A1'].to_numpy()\n",
    "vA2 = df['A2'].to_numpy()\n",
    "Npulses = 1*(vA1>0.) + 1*(vA2>0.)\n",
    "unique, counts = np.unique(Npulses, return_counts=True)\n",
    "print('Number 0, 1, and 2 pulse waveforms: ' + str(counts))\n",
    "\n",
    "# Add column with number of pulses\n",
    "df['Npulses'] = Npulses\n",
    "\n",
    "# Make slices containing only 0,1,2 identified pulses\n",
    "dfno_pulses = df[(df.A1==0) & (df.A2==0)]\n",
    "dfone_pulse = df[(df.A1!=0) & (df.A2==0)]\n",
    "dftwo_pulse = df[(df.A1!=0) & (df.A2!=0)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "waveform (InputLayer)        [(None, 128, 1)]          0         \n",
      "_________________________________________________________________\n",
      "Npulse_conv_layer1 (Conv1D)  (None, 97, 128)           4224      \n",
      "_________________________________________________________________\n",
      "Npulse_conv_layer2 (Conv1D)  (None, 82, 32)            65568     \n",
      "_________________________________________________________________\n",
      "Npulse_conv_layer3 (Conv1D)  (None, 79, 32)            4128      \n",
      "_________________________________________________________________\n",
      "Npulse_flatten (Flatten)     (None, 2528)              0         \n",
      "_________________________________________________________________\n",
      "Npulse_layer1 (Dense)        (None, 32)                80928     \n",
      "_________________________________________________________________\n",
      "Npulse_layer2 (Dense)        (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "Npulse_layer3 (Dense)        (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "Npulse_layer4 (Dense)        (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "Npulse_layer5 (Dense)        (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "Npulse_output (Dense)        (None, 3)                 27        \n",
      "=================================================================\n",
      "Total params: 160,387\n",
      "Trainable params: 160,387\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, Lambda, Conv1D\n",
    "from tensorflow.keras.optimizers import SGD, Adamax, Adadelta\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.losses\n",
    "import tensorflow as tf\n",
    "\n",
    "def customLoss(y_true, y_pred):\n",
    "    y_diff = K.round(y_pred) - y_true\n",
    "    y_loss = y_diff*y_diff\n",
    "    return y_loss\n",
    "\n",
    "inputs     = Input(shape=(NINPUTS,1), name='waveform')\n",
    "x = Conv1D(128,(32), name='Npulse_conv_layer1', activation='tanh')(inputs)\n",
    "x = Conv1D(32,(16), name='Npulse_conv_layer2', activation='tanh')(x)\n",
    "x = Conv1D(32,(4), name='Npulse_conv_layer3', activation='relu')(x)\n",
    "x = Flatten(name='Npulse_flatten')(x)\n",
    "x = Dense(32, name='Npulse_layer1', activation='linear')(x)\n",
    "x = Dense(64, name='Npulse_layer2', activation='tanh')(x)\n",
    "x = Dense(32, name='Npulse_layer3', activation='linear')(x)\n",
    "x = Dense(32, name='Npulse_layer4', activation='tanh')(x)\n",
    "x = Dense(8, name='Npulse_layer5', activation='linear')(x)\n",
    "outputs = Dense(3, name='Npulse_output', activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()\n",
    "\n",
    "#opt = Adam()\n",
    "opt = Adadelta(clipnorm=1, learning_rate=0.002, rho=0.98)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'], weighted_metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_weight: {0: 1.5085, 1: 3.017, 2: 177.47058823529412}\n",
      "Epoch 1/100\n",
      "38014/38014 [==============================] - 253s 7ms/step - loss: 5.2960 - accuracy: 0.9780 - weighted_accuracy: 0.6533 - val_loss: 0.0545 - val_accuracy: 0.9893 - val_weighted_accuracy: 0.9893\n",
      "Epoch 2/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 5.6057 - accuracy: 0.9896 - weighted_accuracy: 0.6622 - val_loss: 0.0538 - val_accuracy: 0.9898 - val_weighted_accuracy: 0.9898\n",
      "Epoch 3/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 5.4317 - accuracy: 0.9899 - weighted_accuracy: 0.6625 - val_loss: 0.0511 - val_accuracy: 0.9900 - val_weighted_accuracy: 0.9900\n",
      "Epoch 4/100\n",
      "38014/38014 [==============================] - 235s 6ms/step - loss: 5.1997 - accuracy: 0.9901 - weighted_accuracy: 0.6627 - val_loss: 0.0500 - val_accuracy: 0.9902 - val_weighted_accuracy: 0.9902\n",
      "Epoch 5/100\n",
      "38014/38014 [==============================] - 252s 7ms/step - loss: 5.0092 - accuracy: 0.9903 - weighted_accuracy: 0.6629 - val_loss: 0.0478 - val_accuracy: 0.9903 - val_weighted_accuracy: 0.9903\n",
      "Epoch 6/100\n",
      "38014/38014 [==============================] - 251s 7ms/step - loss: 4.8362 - accuracy: 0.9903 - weighted_accuracy: 0.6629 - val_loss: 0.0479 - val_accuracy: 0.9903 - val_weighted_accuracy: 0.9903\n",
      "Epoch 7/100\n",
      "38014/38014 [==============================] - 235s 6ms/step - loss: 4.6578 - accuracy: 0.9904 - weighted_accuracy: 0.6630 - val_loss: 0.0471 - val_accuracy: 0.9905 - val_weighted_accuracy: 0.9905\n",
      "Epoch 8/100\n",
      "38014/38014 [==============================] - 220s 6ms/step - loss: 4.5159 - accuracy: 0.9905 - weighted_accuracy: 0.6638 - val_loss: 0.0459 - val_accuracy: 0.9905 - val_weighted_accuracy: 0.9905\n",
      "Epoch 9/100\n",
      "38014/38014 [==============================] - 219s 6ms/step - loss: 4.3635 - accuracy: 0.9905 - weighted_accuracy: 0.6650 - val_loss: 0.0453 - val_accuracy: 0.9904 - val_weighted_accuracy: 0.9904\n",
      "Epoch 10/100\n",
      "38014/38014 [==============================] - 219s 6ms/step - loss: 4.2825 - accuracy: 0.9906 - weighted_accuracy: 0.6697 - val_loss: 0.0454 - val_accuracy: 0.9906 - val_weighted_accuracy: 0.9906\n",
      "Epoch 11/100\n",
      "38014/38014 [==============================] - 236s 6ms/step - loss: 4.1518 - accuracy: 0.9908 - weighted_accuracy: 0.6775 - val_loss: 0.0436 - val_accuracy: 0.9907 - val_weighted_accuracy: 0.9907\n",
      "Epoch 12/100\n",
      "38014/38014 [==============================] - 237s 6ms/step - loss: 3.9520 - accuracy: 0.9910 - weighted_accuracy: 0.6910 - val_loss: 0.0440 - val_accuracy: 0.9906 - val_weighted_accuracy: 0.9906\n",
      "Epoch 13/100\n",
      "38014/38014 [==============================] - 220s 6ms/step - loss: 3.8519 - accuracy: 0.9911 - weighted_accuracy: 0.6988 - val_loss: 0.0423 - val_accuracy: 0.9908 - val_weighted_accuracy: 0.9908\n",
      "Epoch 14/100\n",
      "38014/38014 [==============================] - 219s 6ms/step - loss: 3.7891 - accuracy: 0.9912 - weighted_accuracy: 0.7042 - val_loss: 0.0424 - val_accuracy: 0.9906 - val_weighted_accuracy: 0.9906\n",
      "Epoch 15/100\n",
      "38014/38014 [==============================] - 218s 6ms/step - loss: 3.7419 - accuracy: 0.9914 - weighted_accuracy: 0.7120 - val_loss: 0.0424 - val_accuracy: 0.9908 - val_weighted_accuracy: 0.9908\n",
      "Epoch 16/100\n",
      "38014/38014 [==============================] - 214s 6ms/step - loss: 3.7480 - accuracy: 0.9914 - weighted_accuracy: 0.7120 - val_loss: 0.0410 - val_accuracy: 0.9910 - val_weighted_accuracy: 0.9910\n",
      "Epoch 17/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 3.6724 - accuracy: 0.9916 - weighted_accuracy: 0.7210 - val_loss: 0.0409 - val_accuracy: 0.9911 - val_weighted_accuracy: 0.9911\n",
      "Epoch 18/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 3.6203 - accuracy: 0.9916 - weighted_accuracy: 0.7240 - val_loss: 0.0407 - val_accuracy: 0.9913 - val_weighted_accuracy: 0.9913\n",
      "Epoch 19/100\n",
      "38014/38014 [==============================] - 214s 6ms/step - loss: 3.6225 - accuracy: 0.9917 - weighted_accuracy: 0.7245 - val_loss: 0.0405 - val_accuracy: 0.9912 - val_weighted_accuracy: 0.9912\n",
      "Epoch 20/100\n",
      "38014/38014 [==============================] - 231s 6ms/step - loss: 3.5618 - accuracy: 0.9918 - weighted_accuracy: 0.7299 - val_loss: 0.0407 - val_accuracy: 0.9913 - val_weighted_accuracy: 0.9913\n",
      "Epoch 21/100\n",
      "38014/38014 [==============================] - 231s 6ms/step - loss: 3.5014 - accuracy: 0.9918 - weighted_accuracy: 0.7318 - val_loss: 0.0413 - val_accuracy: 0.9913 - val_weighted_accuracy: 0.9913\n",
      "Epoch 22/100\n",
      "38014/38014 [==============================] - 226s 6ms/step - loss: 3.4736 - accuracy: 0.9919 - weighted_accuracy: 0.7369 - val_loss: 0.0402 - val_accuracy: 0.9912 - val_weighted_accuracy: 0.9912\n",
      "Epoch 23/100\n",
      "38014/38014 [==============================] - 227s 6ms/step - loss: 3.4261 - accuracy: 0.9920 - weighted_accuracy: 0.7427 - val_loss: 0.0399 - val_accuracy: 0.9912 - val_weighted_accuracy: 0.9912\n",
      "Epoch 24/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 3.3370 - accuracy: 0.9920 - weighted_accuracy: 0.7473 - val_loss: 0.0395 - val_accuracy: 0.9914 - val_weighted_accuracy: 0.9914\n",
      "Epoch 25/100\n",
      "38014/38014 [==============================] - 214s 6ms/step - loss: 3.2589 - accuracy: 0.9921 - weighted_accuracy: 0.7493 - val_loss: 0.0395 - val_accuracy: 0.9913 - val_weighted_accuracy: 0.9913\n",
      "Epoch 26/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 3.1225 - accuracy: 0.9921 - weighted_accuracy: 0.7596 - val_loss: 0.0392 - val_accuracy: 0.9914 - val_weighted_accuracy: 0.9914\n",
      "Epoch 27/100\n",
      "38014/38014 [==============================] - 232s 6ms/step - loss: 3.0665 - accuracy: 0.9922 - weighted_accuracy: 0.7662 - val_loss: 0.0385 - val_accuracy: 0.9913 - val_weighted_accuracy: 0.9913\n",
      "Epoch 28/100\n",
      "38014/38014 [==============================] - 233s 6ms/step - loss: 2.9936 - accuracy: 0.9924 - weighted_accuracy: 0.7713 - val_loss: 0.0373 - val_accuracy: 0.9915 - val_weighted_accuracy: 0.9915\n",
      "Epoch 29/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.9161 - accuracy: 0.9924 - weighted_accuracy: 0.7771 - val_loss: 0.0368 - val_accuracy: 0.9915 - val_weighted_accuracy: 0.9915\n",
      "Epoch 30/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.8161 - accuracy: 0.9925 - weighted_accuracy: 0.7817 - val_loss: 0.0376 - val_accuracy: 0.9916 - val_weighted_accuracy: 0.9916\n",
      "Epoch 31/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.8009 - accuracy: 0.9925 - weighted_accuracy: 0.7844 - val_loss: 0.0366 - val_accuracy: 0.9915 - val_weighted_accuracy: 0.9915\n",
      "Epoch 32/100\n",
      "38014/38014 [==============================] - 231s 6ms/step - loss: 2.7403 - accuracy: 0.9926 - weighted_accuracy: 0.7913 - val_loss: 0.0362 - val_accuracy: 0.9916 - val_weighted_accuracy: 0.9916\n",
      "Epoch 33/100\n",
      "38014/38014 [==============================] - 232s 6ms/step - loss: 2.7332 - accuracy: 0.9926 - weighted_accuracy: 0.7906 - val_loss: 0.0364 - val_accuracy: 0.9916 - val_weighted_accuracy: 0.9916\n",
      "Epoch 34/100\n",
      "38014/38014 [==============================] - 232s 6ms/step - loss: 2.6917 - accuracy: 0.9927 - weighted_accuracy: 0.7956 - val_loss: 0.0370 - val_accuracy: 0.9915 - val_weighted_accuracy: 0.9915\n",
      "Epoch 35/100\n",
      "38014/38014 [==============================] - 231s 6ms/step - loss: 2.6573 - accuracy: 0.9928 - weighted_accuracy: 0.8011 - val_loss: 0.0374 - val_accuracy: 0.9914 - val_weighted_accuracy: 0.9914\n",
      "Epoch 36/100\n",
      "38014/38014 [==============================] - 226s 6ms/step - loss: 2.5953 - accuracy: 0.9928 - weighted_accuracy: 0.8056 - val_loss: 0.0369 - val_accuracy: 0.9917 - val_weighted_accuracy: 0.9917\n",
      "Epoch 37/100\n",
      "38014/38014 [==============================] - 225s 6ms/step - loss: 2.5253 - accuracy: 0.9929 - weighted_accuracy: 0.8107 - val_loss: 0.0361 - val_accuracy: 0.9920 - val_weighted_accuracy: 0.9920\n",
      "Epoch 38/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.4738 - accuracy: 0.9930 - weighted_accuracy: 0.8142 - val_loss: 0.0366 - val_accuracy: 0.9918 - val_weighted_accuracy: 0.9918\n",
      "Epoch 39/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.4018 - accuracy: 0.9931 - weighted_accuracy: 0.8208 - val_loss: 0.0359 - val_accuracy: 0.9921 - val_weighted_accuracy: 0.9921\n",
      "Epoch 40/100\n",
      "38014/38014 [==============================] - 230s 6ms/step - loss: 2.3692 - accuracy: 0.9932 - weighted_accuracy: 0.8251 - val_loss: 0.0354 - val_accuracy: 0.9923 - val_weighted_accuracy: 0.9923\n",
      "Epoch 41/100\n",
      "38014/38014 [==============================] - 232s 6ms/step - loss: 2.3082 - accuracy: 0.9932 - weighted_accuracy: 0.8301 - val_loss: 0.0355 - val_accuracy: 0.9923 - val_weighted_accuracy: 0.9923\n",
      "Epoch 42/100\n",
      "38014/38014 [==============================] - 228s 6ms/step - loss: 2.2932 - accuracy: 0.9932 - weighted_accuracy: 0.8320 - val_loss: 0.0363 - val_accuracy: 0.9924 - val_weighted_accuracy: 0.9924\n",
      "Epoch 43/100\n",
      "38014/38014 [==============================] - 228s 6ms/step - loss: 2.2921 - accuracy: 0.9933 - weighted_accuracy: 0.8317 - val_loss: 0.0358 - val_accuracy: 0.9924 - val_weighted_accuracy: 0.9924\n",
      "Epoch 44/100\n",
      "38014/38014 [==============================] - 232s 6ms/step - loss: 2.2598 - accuracy: 0.9933 - weighted_accuracy: 0.8351 - val_loss: 0.0360 - val_accuracy: 0.9924 - val_weighted_accuracy: 0.9924\n",
      "Epoch 45/100\n",
      "38014/38014 [==============================] - 229s 6ms/step - loss: 2.2543 - accuracy: 0.9932 - weighted_accuracy: 0.8324 - val_loss: 0.0362 - val_accuracy: 0.9925 - val_weighted_accuracy: 0.9925\n",
      "Epoch 46/100\n",
      "38014/38014 [==============================] - 252s 7ms/step - loss: 2.2538 - accuracy: 0.9932 - weighted_accuracy: 0.8328 - val_loss: 0.0367 - val_accuracy: 0.9925 - val_weighted_accuracy: 0.9925\n",
      "Epoch 47/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 2.2705 - accuracy: 0.9934 - weighted_accuracy: 0.8363 - val_loss: 0.0361 - val_accuracy: 0.9925 - val_weighted_accuracy: 0.9925\n",
      "Epoch 48/100\n",
      "38014/38014 [==============================] - 255s 7ms/step - loss: 2.2400 - accuracy: 0.9934 - weighted_accuracy: 0.8382 - val_loss: 0.0364 - val_accuracy: 0.9924 - val_weighted_accuracy: 0.9924\n",
      "Epoch 49/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 2.1768 - accuracy: 0.9934 - weighted_accuracy: 0.8436 - val_loss: 0.0364 - val_accuracy: 0.9925 - val_weighted_accuracy: 0.9925\n",
      "Epoch 50/100\n",
      "38014/38014 [==============================] - 240s 6ms/step - loss: 2.2600 - accuracy: 0.9934 - weighted_accuracy: 0.8379 - val_loss: 0.0355 - val_accuracy: 0.9928 - val_weighted_accuracy: 0.9928\n",
      "Epoch 51/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 2.2055 - accuracy: 0.9935 - weighted_accuracy: 0.8417 - val_loss: 0.0352 - val_accuracy: 0.9927 - val_weighted_accuracy: 0.9927\n",
      "Epoch 52/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 2.1360 - accuracy: 0.9935 - weighted_accuracy: 0.8471 - val_loss: 0.0353 - val_accuracy: 0.9928 - val_weighted_accuracy: 0.9928\n",
      "Epoch 53/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 2.1240 - accuracy: 0.9935 - weighted_accuracy: 0.8436 - val_loss: 0.0357 - val_accuracy: 0.9928 - val_weighted_accuracy: 0.9928\n",
      "Epoch 54/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 2.0815 - accuracy: 0.9936 - weighted_accuracy: 0.8472 - val_loss: 0.0359 - val_accuracy: 0.9928 - val_weighted_accuracy: 0.9928\n",
      "Epoch 55/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 2.0044 - accuracy: 0.9937 - weighted_accuracy: 0.8522 - val_loss: 0.0354 - val_accuracy: 0.9931 - val_weighted_accuracy: 0.9931\n",
      "Epoch 56/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.9604 - accuracy: 0.9937 - weighted_accuracy: 0.8546 - val_loss: 0.0352 - val_accuracy: 0.9929 - val_weighted_accuracy: 0.9929\n",
      "Epoch 57/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.9093 - accuracy: 0.9939 - weighted_accuracy: 0.8623 - val_loss: 0.0357 - val_accuracy: 0.9929 - val_weighted_accuracy: 0.9929\n",
      "Epoch 58/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.9569 - accuracy: 0.9938 - weighted_accuracy: 0.8554 - val_loss: 0.0348 - val_accuracy: 0.9930 - val_weighted_accuracy: 0.9930\n",
      "Epoch 59/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.9067 - accuracy: 0.9938 - weighted_accuracy: 0.8627 - val_loss: 0.0343 - val_accuracy: 0.9931 - val_weighted_accuracy: 0.9931\n",
      "Epoch 60/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.9088 - accuracy: 0.9939 - weighted_accuracy: 0.8612 - val_loss: 0.0343 - val_accuracy: 0.9931 - val_weighted_accuracy: 0.9931\n",
      "Epoch 61/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.8670 - accuracy: 0.9940 - weighted_accuracy: 0.8655 - val_loss: 0.0345 - val_accuracy: 0.9929 - val_weighted_accuracy: 0.9929\n",
      "Epoch 62/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.8069 - accuracy: 0.9941 - weighted_accuracy: 0.8717 - val_loss: 0.0348 - val_accuracy: 0.9933 - val_weighted_accuracy: 0.9933\n",
      "Epoch 63/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.7635 - accuracy: 0.9941 - weighted_accuracy: 0.8721 - val_loss: 0.0344 - val_accuracy: 0.9932 - val_weighted_accuracy: 0.9932\n",
      "Epoch 64/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.7679 - accuracy: 0.9941 - weighted_accuracy: 0.8748 - val_loss: 0.0346 - val_accuracy: 0.9932 - val_weighted_accuracy: 0.9932\n",
      "Epoch 65/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.7305 - accuracy: 0.9941 - weighted_accuracy: 0.8779 - val_loss: 0.0350 - val_accuracy: 0.9932 - val_weighted_accuracy: 0.9932\n",
      "Epoch 66/100\n",
      "38014/38014 [==============================] - 245s 6ms/step - loss: 1.7434 - accuracy: 0.9942 - weighted_accuracy: 0.8795 - val_loss: 0.0347 - val_accuracy: 0.9931 - val_weighted_accuracy: 0.9931\n",
      "Epoch 67/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.7168 - accuracy: 0.9942 - weighted_accuracy: 0.8810 - val_loss: 0.0340 - val_accuracy: 0.9932 - val_weighted_accuracy: 0.9932\n",
      "Epoch 68/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.6879 - accuracy: 0.9943 - weighted_accuracy: 0.8829 - val_loss: 0.0344 - val_accuracy: 0.9933 - val_weighted_accuracy: 0.9933\n",
      "Epoch 69/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.6909 - accuracy: 0.9943 - weighted_accuracy: 0.8856 - val_loss: 0.0349 - val_accuracy: 0.9934 - val_weighted_accuracy: 0.9934\n",
      "Epoch 70/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.6532 - accuracy: 0.9943 - weighted_accuracy: 0.8849 - val_loss: 0.0351 - val_accuracy: 0.9933 - val_weighted_accuracy: 0.9933\n",
      "Epoch 71/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.6355 - accuracy: 0.9944 - weighted_accuracy: 0.8884 - val_loss: 0.0351 - val_accuracy: 0.9933 - val_weighted_accuracy: 0.9933\n",
      "Epoch 72/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.5852 - accuracy: 0.9944 - weighted_accuracy: 0.8907 - val_loss: 0.0340 - val_accuracy: 0.9934 - val_weighted_accuracy: 0.9934\n",
      "Epoch 73/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.5422 - accuracy: 0.9945 - weighted_accuracy: 0.8946 - val_loss: 0.0338 - val_accuracy: 0.9934 - val_weighted_accuracy: 0.9934\n",
      "Epoch 74/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.5000 - accuracy: 0.9945 - weighted_accuracy: 0.8965 - val_loss: 0.0345 - val_accuracy: 0.9934 - val_weighted_accuracy: 0.9934\n",
      "Epoch 75/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.5134 - accuracy: 0.9945 - weighted_accuracy: 0.8939 - val_loss: 0.0341 - val_accuracy: 0.9935 - val_weighted_accuracy: 0.9935\n",
      "Epoch 76/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.4833 - accuracy: 0.9945 - weighted_accuracy: 0.8946 - val_loss: 0.0333 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 77/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.4380 - accuracy: 0.9946 - weighted_accuracy: 0.8970 - val_loss: 0.0334 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 78/100\n",
      "38014/38014 [==============================] - 242s 6ms/step - loss: 1.4010 - accuracy: 0.9945 - weighted_accuracy: 0.8985 - val_loss: 0.0337 - val_accuracy: 0.9936 - val_weighted_accuracy: 0.9936\n",
      "Epoch 79/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.4145 - accuracy: 0.9945 - weighted_accuracy: 0.8977 - val_loss: 0.0330 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 80/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.3656 - accuracy: 0.9947 - weighted_accuracy: 0.9021 - val_loss: 0.0335 - val_accuracy: 0.9935 - val_weighted_accuracy: 0.9935\n",
      "Epoch 81/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.3733 - accuracy: 0.9947 - weighted_accuracy: 0.9021 - val_loss: 0.0338 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 82/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.3461 - accuracy: 0.9947 - weighted_accuracy: 0.9024 - val_loss: 0.0327 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 83/100\n",
      "38014/38014 [==============================] - 245s 6ms/step - loss: 1.3157 - accuracy: 0.9947 - weighted_accuracy: 0.9059 - val_loss: 0.0333 - val_accuracy: 0.9934 - val_weighted_accuracy: 0.9934\n",
      "Epoch 84/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.3247 - accuracy: 0.9947 - weighted_accuracy: 0.9055 - val_loss: 0.0332 - val_accuracy: 0.9935 - val_weighted_accuracy: 0.9935\n",
      "Epoch 85/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.3214 - accuracy: 0.9947 - weighted_accuracy: 0.9063 - val_loss: 0.0332 - val_accuracy: 0.9935 - val_weighted_accuracy: 0.9935\n",
      "Epoch 86/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.3000 - accuracy: 0.9948 - weighted_accuracy: 0.9063 - val_loss: 0.0327 - val_accuracy: 0.9936 - val_weighted_accuracy: 0.9936\n",
      "Epoch 87/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.2994 - accuracy: 0.9948 - weighted_accuracy: 0.9090 - val_loss: 0.0332 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 88/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.2633 - accuracy: 0.9948 - weighted_accuracy: 0.9101 - val_loss: 0.0325 - val_accuracy: 0.9938 - val_weighted_accuracy: 0.9938\n",
      "Epoch 89/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.2223 - accuracy: 0.9948 - weighted_accuracy: 0.9133 - val_loss: 0.0334 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 90/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.2407 - accuracy: 0.9949 - weighted_accuracy: 0.9103 - val_loss: 0.0326 - val_accuracy: 0.9938 - val_weighted_accuracy: 0.9938\n",
      "Epoch 91/100\n",
      "38014/38014 [==============================] - 243s 6ms/step - loss: 1.1973 - accuracy: 0.9949 - weighted_accuracy: 0.9160 - val_loss: 0.0328 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 92/100\n",
      "38014/38014 [==============================] - 244s 6ms/step - loss: 1.1838 - accuracy: 0.9951 - weighted_accuracy: 0.9184 - val_loss: 0.0320 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 93/100\n",
      "38014/38014 [==============================] - 241s 6ms/step - loss: 1.1552 - accuracy: 0.9951 - weighted_accuracy: 0.9188 - val_loss: 0.0319 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 94/100\n",
      "38014/38014 [==============================] - 245s 6ms/step - loss: 1.1666 - accuracy: 0.9951 - weighted_accuracy: 0.9196 - val_loss: 0.0325 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 95/100\n",
      "38014/38014 [==============================] - 252s 7ms/step - loss: 1.1167 - accuracy: 0.9951 - weighted_accuracy: 0.9215 - val_loss: 0.0322 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 96/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 1.1143 - accuracy: 0.9952 - weighted_accuracy: 0.9208 - val_loss: 0.0312 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 97/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 1.0761 - accuracy: 0.9952 - weighted_accuracy: 0.9266 - val_loss: 0.0318 - val_accuracy: 0.9937 - val_weighted_accuracy: 0.9937\n",
      "Epoch 98/100\n",
      "38014/38014 [==============================] - 254s 7ms/step - loss: 1.0703 - accuracy: 0.9952 - weighted_accuracy: 0.9239 - val_loss: 0.0317 - val_accuracy: 0.9939 - val_weighted_accuracy: 0.9939\n",
      "Epoch 99/100\n",
      "38014/38014 [==============================] - 253s 7ms/step - loss: 1.0485 - accuracy: 0.9953 - weighted_accuracy: 0.9259 - val_loss: 0.0308 - val_accuracy: 0.9941 - val_weighted_accuracy: 0.9941\n",
      "Epoch 100/100\n",
      "38014/38014 [==============================] - 253s 7ms/step - loss: 1.0556 - accuracy: 0.9953 - weighted_accuracy: 0.9247 - val_loss: 0.0315 - val_accuracy: 0.9938 - val_weighted_accuracy: 0.9938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f426e138ac8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf = df\n",
    "y_labels      = mydf['Npulses']   # Peel off only 5 labels\n",
    "y_cat_labels  = tf.keras.utils.to_categorical( y_labels, 3 )\n",
    "x_waveform    = mydf.iloc[:,5:133]  # Peel off 128 waveform samples\n",
    "\n",
    "# account for imbalanced samples\n",
    "no_pulse_weight  = len(df)/len(dfno_pulses)\n",
    "one_pulse_weight = len(df)/len(dfone_pulse)\n",
    "two_pulse_weight = len(df)/len(dftwo_pulse)\n",
    "class_weight = {0:no_pulse_weight, 1:one_pulse_weight, 2:two_pulse_weight}\n",
    "print('class_weight: ' + str(class_weight))\n",
    "\n",
    "BATCH  = 4\n",
    "EPOCHS = 100\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    'val_mae',\n",
    "    min_delta=0.002,\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.fit(x_waveform, y_cat_labels, class_weight=class_weight, batch_size=BATCH, epochs=EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.10.13.tf2.3.1/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: 2020.10.31.Npulses/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('2020.11.01.Npulses')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the accuracy of the model in predicting the number of pulses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['Npulses'].to_numpy()\n",
    "y_pred = model.predict(mydf.iloc[:,5:133])\n",
    "y_pred = np.squeeze(np.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total waveforms: 190071  (126000 - 0 pulse, 63000 - 1 pulse, 1071 - 2 pulse)\n",
      "Zero pulse waveforms: 124223 correct, 1777 incorrect (1.4%)\n",
      "One pulse waveforms: 61706 correct, 1294 incorrect (2.1%)\n",
      "Two pulse waveforms: 0 correct, 1071 incorrect (100.0%)\n"
     ]
    }
   ],
   "source": [
    "y_diff = y_pred - y_true\n",
    "testdf = pd.DataFrame({'y_diff':y_diff, 'y_true':y_true, 'y_pred':y_pred})\n",
    "\n",
    "N_zero_pulse = len(testdf[ (testdf['y_true']==0) ])\n",
    "N_one_pulse = len(testdf[ (testdf['y_true']==1) ])\n",
    "N_two_pulse = len(testdf[ (testdf['y_true']==2) ])\n",
    "\n",
    "Ngood_zero_pulse = len(testdf[ (testdf['y_diff']==0) & (testdf['y_true']==0) ])\n",
    "Ngood_one_pulse = len(testdf[ (testdf['y_diff']==0) & (testdf['y_true']==1) ])\n",
    "Ngood_two_pulse = len(testdf[ (testdf['y_diff']==0) & (testdf['y_true']==2) ])\n",
    "\n",
    "Nbad_zero_pulse = len(testdf[ (testdf['y_diff']!=0) & (testdf['y_true']==0) ])\n",
    "Nbad_one_pulse = len(testdf[ (testdf['y_diff']!=0) & (testdf['y_true']==1) ])\n",
    "Nbad_two_pulse = len(testdf[ (testdf['y_diff']!=0) & (testdf['y_true']==2) ])\n",
    "\n",
    "percent_bad_zero_pulse = 100.0*Nbad_zero_pulse/(Nbad_zero_pulse+Ngood_zero_pulse)\n",
    "percent_bad_one_pulse = 100.0*Nbad_one_pulse/(Nbad_one_pulse+Ngood_one_pulse)\n",
    "percent_bad_two_pulse = 100.0*Nbad_two_pulse/(Nbad_two_pulse+Ngood_two_pulse)\n",
    "\n",
    "print('Total waveforms: %d  (%d - 0 pulse, %d - 1 pulse, %d - 2 pulse)' % (len(testdf), N_zero_pulse, N_one_pulse, N_two_pulse))\n",
    "print('Zero pulse waveforms: %d correct, %d incorrect (%3.1f%%)' % (Ngood_zero_pulse, Nbad_zero_pulse, percent_bad_zero_pulse))\n",
    "print('One pulse waveforms: %d correct, %d incorrect (%3.1f%%)' % (Ngood_one_pulse, Nbad_one_pulse, percent_bad_one_pulse))\n",
    "print('Two pulse waveforms: %d correct, %d incorrect (%3.1f%%)' % (Ngood_two_pulse, Nbad_two_pulse, percent_bad_two_pulse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2020.10.13.tf2.3.1",
   "language": "python",
   "name": "venv_2020.10.13.tf2.3.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
