{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trackingML DL with GlueX Fall 2018 data part 5\n",
    "\n",
    "Here I am finally ready to put the pieces from the first 4 parts together to try and get a working model that trains the 5 parameters of the tracking state vector using a custom loss function that incorporates the inverse covariance matrix from the traditional tracking result. I use the \"trackingML_features6.csv\" and associated labels file left from the end of part 4. It only has 10k events, but should be sufficient to get a fully working system and to prove we can overtrain with the model.\n",
    "\n",
    "The first step isto read the data into the dataframes. I print the column names again for the labels file just to confirm the format is what is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of input features per track: 5835\n",
      "Number of tracks read: 10  ( 0.10% of total )\n",
      "Label Names: \n",
      "           event\n",
      "           q_over_pt, phi, tanl, D, z\n",
      "              cov_00,    cov_01,    cov_02,    cov_03,    cov_04\n",
      "                         cov_11,    cov_12,    cov_13,    cov_14\n",
      "                                    cov_22,    cov_23,    cov_24\n",
      "                                               cov_33,    cov_34\n",
      "                                                          cov_44\n",
      "           invcov_00, invcov_01, invcov_02, invcov_03, invcov_04\n",
      "           invcov_10, invcov_11, invcov_12, invcov_13, invcov_14\n",
      "           invcov_20, invcov_21, invcov_22, invcov_23, invcov_24\n",
      "           invcov_30, invcov_31, invcov_32, invcov_33, invcov_34\n",
      "           invcov_40, invcov_41, invcov_42, invcov_43, invcov_44\n",
      "           chisq, Ndof, rms\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "TRAIN_FILE  = '/home/davidl/work2/2020.04.30.trackingML/trackingML_features6.csv'\n",
    "LABELS_FILE = '/home/davidl/work2/2020.04.30.trackingML/trackingML_labels6.csv'\n",
    "MAX_TRACKS  = 10  # Number of tracks(lines) to read from training file\n",
    "\n",
    "# Get fraction of features file read so we can estimate fraction of data we're using\n",
    "percent_read = 0.0;\n",
    "with open(TRAIN_FILE) as f:\n",
    "    f.readline()  # skip header\n",
    "    for i in range(100): percent_read = percent_read + float(len(f.readline()) + 1)\n",
    "    percent_read = 100.0*percent_read/os.path.getsize(TRAIN_FILE)*MAX_TRACKS/100.0\n",
    "\n",
    "# NOTE: Only reading first few rows for now since it takes a long time to read entire file\n",
    "df       = pd.read_csv(TRAIN_FILE  , nrows=MAX_TRACKS)\n",
    "labelsdf = pd.read_csv(LABELS_FILE , nrows=MAX_TRACKS)\n",
    "\n",
    "NINPUTS = len(df.columns)\n",
    "\n",
    "print('\\n\\nNumber of input features per track: %d' % NINPUTS)\n",
    "print('Number of tracks read: %d  ( %3.2f%% of total )' % (len(df.index), percent_read))\n",
    "print('Label Names: ')\n",
    "print('           ' + ', '.join(labelsdf.columns[0:1])) # event\n",
    "print('           ' + ', '.join(labelsdf.columns[1:6])) # q_over_pt, phi, tanl, D, z\n",
    "print('              ' + '           '*0 + ',    '.join(labelsdf.columns[6:11])) # cov_01 - cov_04\n",
    "print('              ' + '           '*1 + ',    '.join(labelsdf.columns[11:15])) # cov_11 - cov_14\n",
    "print('              ' + '           '*2 + ',    '.join(labelsdf.columns[15:18])) # cov_22 - cov_24\n",
    "print('              ' + '           '*3 + ',    '.join(labelsdf.columns[18:20])) # cov_33 - cov_34\n",
    "print('              ' + '           '*4 + ',    '.join(labelsdf.columns[20:21])) # cov_44\n",
    "print('           ' + ', '.join(labelsdf.columns[21:26])) # invcov_00 - invcov_04\n",
    "print('           ' + ', '.join(labelsdf.columns[26:31])) # invcov_10 - invcov_14\n",
    "print('           ' + ', '.join(labelsdf.columns[31:36])) # invcov_20 - invcov_24\n",
    "print('           ' + ', '.join(labelsdf.columns[36:41])) # invcov_30 - invcov_34\n",
    "print('           ' + ', '.join(labelsdf.columns[41:46])) # invcov_40 - invcov_44\n",
    "print('           ' + ', '.join(labelsdf.columns[46:]))   # chisq, Ndof, rms\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global parameters\n",
    "\n",
    "Here I define some gobal parameters used later. Gathering them here makes it a little easier to manage globally as opposed to burying them in the code. Even if it means re-running some cells when these need to change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NINPUTS = len(df.columns) # Number of input values(features) per track\n",
    "\n",
    "GPUS   = 0  # 0=force CPU, otherwise, the number of GPUs to use\n",
    "Nouts  = 200 # For Lamda layers that use MyWeightedAvg()\n",
    "\n",
    "#------------- Define output bin values and ranges\n",
    "DMIN   = -12.0\n",
    "DMAX   =  12.0\n",
    "D_BINSIZE = (DMAX-DMIN)/Nouts\n",
    "\n",
    "PHIMIN   = -3.5\n",
    "PHIMAX   =  3.5\n",
    "PHI_BINSIZE = (PHIMAX-PHIMIN)/Nouts\n",
    "\n",
    "QOVERPt_MIN   = -2000.0\n",
    "QOVERPt_MAX   =  2000.0\n",
    "QOVERPt_BINSIZE = (QOVERPt_MAX-QOVERPt_MIN)/Nouts\n",
    "\n",
    "TANLMIN   = -10.0\n",
    "TANLMAX   = 400.0\n",
    "TANL_BINSIZE = (TANLMAX-TANLMIN)/Nouts\n",
    "\n",
    "ZMIN   = -100.0\n",
    "ZMAX   =  400.0\n",
    "Z_BINSIZE = (ZMAX-ZMIN)/Nouts\n",
    "#--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layer Definition\n",
    "\n",
    "This is just copied from part 2 for convenience, but the model is beefed up a bit with additional layers.\n",
    "\n",
    "This section defines the layers of the model. It actually just defines some procedures that aren't executed until a couple of cells later. (That is when any errors will come up.)\n",
    "\n",
    "To make things easier to maintain, different parts of the model are defined in different procedures. The structure is shown in the diagram below. Note that these make use of a Lambda layer which uses the MyWeightedAvg procedure defined at the bottom of the cell. Lamda's are nice for making simple custom layers without the complexity of full custom layers.\n",
    "\n",
    "![ModelDiagram.png](ModelDiagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import SGD, Adamax, Adadelta\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.losses\n",
    "import tensorflow as tf\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineCommonModel\n",
    "#-----------------------------------------------------\n",
    "def DefineCommonModel(inputs):\n",
    "    x = Flatten(name='top_layer1')(inputs)\n",
    "    x = Dense(int(Nouts*5), name='common_layer1', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(int(Nouts), name='common_layer2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(int(Nouts), name='common_layer3', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(int(Nouts), name='common_layer4', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(int(Nouts), name='common_layer5', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineDModel\n",
    "#-----------------------------------------------------\n",
    "def DefineDModel(inputs):\n",
    "    x = Dense(Nouts, name='D_output_dist1', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='D_output_dist2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='D_output_dist3', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='D_output_dist4', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='D_output', arguments={'binsize':D_BINSIZE, 'xmin':DMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefinePhiModel\n",
    "#-----------------------------------------------------\n",
    "def DefinePhiModel(inputs):\n",
    "    x = Dense(Nouts, name='phi_output_dist1', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='phi_output_dist2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='phi_output_dist3', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='phi_output_dist4', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='phi_output', arguments={'binsize':PHI_BINSIZE, 'xmin':PHIMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Define_q_over_pt_Model\n",
    "#-----------------------------------------------------\n",
    "def Define_q_over_pt_Model(inputs):\n",
    "    x = Dense(Nouts, name='q_over_pt_output_dist1', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='q_over_pt_output_dist2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='q_over_pt_output_dist3', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='q_over_pt_output_dist4', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='q_over_pt_output', arguments={'binsize':QOVERPt_BINSIZE, 'xmin':QOVERPt_MIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Define_tanl_Model\n",
    "#-----------------------------------------------------\n",
    "def Define_tanl_Model(inputs):\n",
    "    x = Dense(Nouts, name='tanl_output_dist1', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='tanl_output_dist2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='tanl_output_dist3', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='tanl_output_dist4', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='tanl_output', arguments={'binsize':TANL_BINSIZE, 'xmin':TANLMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineZModel\n",
    "#-----------------------------------------------------\n",
    "def DefineZModel(inputs):\n",
    "    x = Dense(Nouts, name='z_output_dist1', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='z_output_dist2', activation='tanh', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='z_output_dist3', activation='linear', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Dense(Nouts, name='z_output_dist4', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='z_output', arguments={'binsize':Z_BINSIZE, 'xmin':ZMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineCommonOutput\n",
    "#-----------------------------------------------------\n",
    "def DefineCommonOutput(inputs):\n",
    "    x = tf.keras.layers.concatenate( inputs )\n",
    "    x = Dense(Nouts, name='common_out1', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='common_out2', activation='tanh', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(Nouts, name='common_out3', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    x = Dense(5, name='outputs', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# MyWeightedAvg\n",
    "#\n",
    "# This is used by the final Lambda layer in each branch\n",
    "# of the network. It defines the formula for calculating\n",
    "# the weighted average of the inputs from the previous\n",
    "# layer.\n",
    "#-----------------------------------------------------\n",
    "def MyWeightedAvg(inputs, binsize, xmin):\n",
    "    ones = K.ones_like(inputs[0,:])                       # [1, 1, 1, 1....]   (size Nouts)\n",
    "    idx  = K.cumsum(ones)                                 # [1, 2, 3, 4....]   (size Nouts)\n",
    "    norm = K.sum(inputs, axis=1, keepdims=True)           # normalization of all outputs by batch. shape is 1D array of size batch (n.b. keepdims=True is critical!)\n",
    "    wsum = K.sum(idx*inputs, axis=1, keepdims=True)/norm  # array of size batch with weighted avg. of mean in units of bins (n.b. keepdims=True is critical!)\n",
    "    output = (binsize*(wsum-0.5)) + xmin                  # convert from bins to physical units (shape batch,1)\n",
    "\n",
    "    print('MyWeightedAvg:')\n",
    "    print('       binsize = %f' % binsize)\n",
    "    print('          xmin = %f' % xmin)\n",
    "    print('   input shape = %s' % str(inputs.shape))\n",
    "    print('  output shape = %s' % str(output.shape))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "The full model is put together here using the parts defined in the previous cell. It also defines weights for the trivial loss function used. The weights are used here as a way of scaling the loss for each of the state parameters by $1/\\sigma_i$ to account for the different units and uncertainties. This is actually not going to be sufficient in the end where full custom loss function will be required. It at least gives a simple example that can be used for the this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "# DefineModel\n",
    "#-----------------------------------------------------\n",
    "# This is used to define the model. It is only called if no model\n",
    "# file is found in the model_checkpoints directory.\n",
    "def DefineModel():\n",
    "\n",
    "    # If GPUS==0 this will force use of CPU, even if GPUs are present\n",
    "    # If GPUS>1 this will force the CPU to serve as orchestrator\n",
    "    # If GPUS==1 this will do nothing, allowing GPU to act as its own orchestrator\n",
    "    if GPUS!=1: tf.device('/cpu:0')\n",
    "\n",
    "    # Here we build the network model.\n",
    "    # This model is made of multiple parts. The first handles the\n",
    "    # inputs and identifies common features. The rest are branches with\n",
    "    # each determining an output parameter from those features.\n",
    "    inputs         = Input(shape=(NINPUTS,), name='image_inputs')\n",
    "    commonmodel    = DefineCommonModel(inputs)\n",
    "    Dmodel         = DefinePhiModel(         commonmodel )\n",
    "    phimodel       = DefineDModel(           commonmodel )\n",
    "    q_over_ptmodel = Define_q_over_pt_Model( commonmodel )\n",
    "    tanlmodel      = Define_tanl_Model(      commonmodel )\n",
    "    zmodel         = DefineZModel(           commonmodel )\n",
    "    commonoutput   = DefineCommonOutput([Dmodel, phimodel, q_over_ptmodel, tanlmodel, zmodel])\n",
    "\n",
    "    # Custom loss function requires additional inputs (inverse covariance matrix)\n",
    "    # We must use the \"add_loss\" method to get around restrictions that prevent\n",
    "    # us from just passing them in as extra labels. See:\n",
    "    # https://stackoverflow.com/questions/62154660/keras-valueerror-dimensions-must-be-equal-how-to-pass-label-dependent-values\n",
    "    input_true     = Input(shape=(5,), name='state_true')\n",
    "    input_incov    = Input(shape=(5*5,), name='invcov')\n",
    "    all_inputs     = [inputs, input_incov, input_true]\n",
    "    \n",
    "    model          = Model(inputs=all_inputs, outputs=commonoutput)\n",
    "\n",
    "    # Compile the model, possibly using multiple GPUs\n",
    "    opt = Adadelta(clipnorm=1.0)\n",
    "    if GPUS<=1 :\n",
    "        final_model = model\n",
    "    else:\n",
    "        final_model = multi_gpu_model( model, gpus=GPUS )\n",
    "\n",
    "    \n",
    "    final_model.add_loss(customLoss( input_true, commonoutput, input_incov ) )\n",
    "    final_model.compile(loss=None, optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "    #final_model.compile(loss=customLoss, optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "    \n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred shape: (3, 5)\n",
      "y_true shape: (3, 5)\n",
      "invcov shape: (3, 25)\n",
      "loss shape: (3,)\n",
      "[0.32499945 0.32499945 0.32499945]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss(y_true, y_pred, invcov):\n",
    "\n",
    "    batch_size = tf.shape(y_pred)[0]  # n.b. y_pred.shape[0] will not work for some reason in tf1\n",
    "    print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "    print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 5)\n",
    "    print('invcov shape: ' + str(invcov.shape) )  # inconv shape is (batch, 25)\n",
    "    \n",
    "    y_pred = K.reshape(y_pred, (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "    y_true = K.reshape(y_true, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "    invcov = K.reshape(invcov, (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "    \n",
    "    # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "    invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "    \n",
    "    # Difference between prediction and true state vectors\n",
    "    y_diff = y_pred - y_true\n",
    "    \n",
    "    # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "    y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "    y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "    y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "    y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "    return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "x_test = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "y_test = [1.1, 2.1, 3.1, 4.1, 5.1]\n",
    "inconv_test = np.arange(0.1, 2.6, 0.1).tolist()\n",
    "\n",
    "loss = K.eval(customLoss(K.variable([x_test,x_test,x_test]), K.variable([y_test,y_test,y_test]), K.variable([inconv_test,inconv_test,inconv_test])))\n",
    "print('loss shape: '    + str(loss.shape)    )\n",
    "print(loss)\n",
    "\n",
    "#--------------------------------------------\n",
    "# Define custom loss function \n",
    "def customLoss2(y_true, y_pred):\n",
    "\n",
    "    batch_size = tf.shape(y_pred)[0]  # n.b. y_pred.shape[0] will not work for some reason in tf1\n",
    "    print('y_pred shape: ' + str(y_pred.shape) )  # y_pred shape is (batch, 5)\n",
    "    print('y_true shape: ' + str(y_true.shape) )  # y_true shape is (batch, 49)\n",
    "    print('y_pred type: ' + str(type(y_pred) ) )  # y_pred shape is (batch, 5)\n",
    "    print('y_true type: ' + str(type(y_true) ) )  # y_true shape is (batch, 49)\n",
    "\n",
    "    # Note that y_pred only has the 5 state vector parameters while y_true contains\n",
    "    # all of the labels (event, state vector, covariance matrix, inverse cov., ...)\n",
    "    # We peel off the state vector and inverse covariance here which are the parts\n",
    "    # we need.\n",
    "    y_state = y_true[:,1:6]                         # y_state shape is now (batch, 5)\n",
    "    invcov  = y_true[:,21:46]                       # invcov  shape is now (batch, 25)\n",
    "    \n",
    "    y_pred  = K.reshape(y_pred,  (batch_size, 5,1)) # y_pred  shape is now (batch, 5,1)\n",
    "    y_state = K.reshape(y_state, (batch_size, 5,1)) # y_state shape is now (batch, 5,1)\n",
    "    invcov  = K.reshape(invcov,  (batch_size, 5,5)) # invcov  shape is now (batch, 5,5)\n",
    "    \n",
    "    # n.b. we must use tf.transpose here an not K.transpose since the latter does not allow perm argument\n",
    "    invcov = tf.transpose(invcov, perm=[0,2,1])     # invcov shape is now (batch, 5,5)\n",
    "    \n",
    "    # Difference between prediction and true state vectors\n",
    "    y_diff = y_pred - y_state\n",
    "    \n",
    "    # n.b. use \"batch_dot\" and not \"dot\"!\n",
    "    y_dot = K.batch_dot(invcov, y_diff)           # y_dot shape is (batch,5,1)\n",
    "    y_dot = K.reshape(y_dot, (batch_size, 1, 5))  # y_dot shape is now (batch,1,5)\n",
    "    y_loss = K.batch_dot(y_dot, y_diff)           # y_loss shape is (batch,1,1)\n",
    "    y_loss = K.reshape(y_loss, (batch_size,))     # y_loss shape is now (batch)\n",
    "    return y_loss\n",
    "\n",
    "#--------------------------------------------\n",
    "# Test loss function\n",
    "#xx = np.arange(0.1, 4.9, 0.1).tolist()\n",
    "#yy = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "\n",
    "#loss = K.eval(customLoss(K.variable([xx,xx,xx]), K.variable([yy,yy,yy])))\n",
    "#print('loss shape: '    + str(loss.shape)    )\n",
    "#print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Build model\n",
    "\n",
    "I have found in the past that it is often good to be able to load a model that has undergone some training and continue training it. In addition, it is useful if you can keep track of how many epochs total were used in the training. In this cell, I look for the most recent model file and load it, if found. If no model file is found, then the model is defined using the above routines.\n",
    "\n",
    "Note that at the end of this the \"epochs_loaded\" parameter will be set to the number of epochs completed already for this model (0 if it is new). This number is passed into the fit call later so it displays the right thing and, in turn, passes it to the routine that saves the model periodically so that it can name the file properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find saved model. Will start from scratch\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.035000\n",
      "          xmin = -3.500000\n",
      "   input shape = (None, 200)\n",
      "  output shape = (None, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.120000\n",
      "          xmin = -12.000000\n",
      "   input shape = (None, 200)\n",
      "  output shape = (None, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 20.000000\n",
      "          xmin = -2000.000000\n",
      "   input shape = (None, 200)\n",
      "  output shape = (None, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 2.050000\n",
      "          xmin = -10.000000\n",
      "   input shape = (None, 200)\n",
      "  output shape = (None, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 2.500000\n",
      "          xmin = -100.000000\n",
      "   input shape = (None, 200)\n",
      "  output shape = (None, 1)\n",
      "y_pred shape: (None, 5)\n",
      "y_true shape: (None, 5)\n",
      "invcov shape: (None, 25)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_inputs (InputLayer)       [(None, 5835)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "top_layer1 (Flatten)            (None, 5835)         0           image_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "common_layer1 (Dense)           (None, 1000)         5836000     top_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "common_layer2 (Dense)           (None, 200)          200200      common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "common_layer3 (Dense)           (None, 200)          40200       common_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "common_layer4 (Dense)           (None, 200)          40200       common_layer3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "common_layer5 (Dense)           (None, 200)          40200       common_layer4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi_output_dist1 (Dense)        (None, 200)          40200       common_layer5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "D_output_dist1 (Dense)          (None, 200)          40200       common_layer5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output_dist1 (Dense)  (None, 200)          40200       common_layer5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output_dist1 (Dense)       (None, 200)          40200       common_layer5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi_output_dist2 (Dense)        (None, 200)          40200       phi_output_dist1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "D_output_dist2 (Dense)          (None, 200)          40200       D_output_dist1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output_dist2 (Dense)  (None, 200)          40200       q_over_pt_output_dist1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output_dist2 (Dense)       (None, 200)          40200       tanl_output_dist1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "phi_output_dist3 (Dense)        (None, 200)          40200       phi_output_dist2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "D_output_dist3 (Dense)          (None, 200)          40200       D_output_dist2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output_dist3 (Dense)  (None, 200)          40200       q_over_pt_output_dist2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output_dist3 (Dense)       (None, 200)          40200       tanl_output_dist2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "phi_output_dist4 (Dense)        (None, 200)          40200       phi_output_dist3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "D_output_dist4 (Dense)          (None, 200)          40200       D_output_dist3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output_dist4 (Dense)  (None, 200)          40200       q_over_pt_output_dist3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output_dist4 (Dense)       (None, 200)          40200       tanl_output_dist3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "z_output_dist4 (Dense)          (None, 200)          40200       common_layer5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi_output (Lambda)             (None, 1)            0           phi_output_dist4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "D_output (Lambda)               (None, 1)            0           D_output_dist4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output (Lambda)       (None, 1)            0           q_over_pt_output_dist4[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output (Lambda)            (None, 1)            0           tanl_output_dist4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "z_output (Lambda)               (None, 1)            0           z_output_dist4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5)            0           phi_output[0][0]                 \n",
      "                                                                 D_output[0][0]                   \n",
      "                                                                 q_over_pt_output[0][0]           \n",
      "                                                                 tanl_output[0][0]                \n",
      "                                                                 z_output[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "common_out1 (Dense)             (None, 200)          1200        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "common_out2 (Dense)             (None, 200)          40200       common_out1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "common_out3 (Dense)             (None, 200)          40200       common_out2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "invcov (InputLayer)             [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "state_true (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            1005        common_out3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Shape (TensorFlowOp [(2,)]               0           outputs[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_strided_slice (Tens [()]                 0           tf_op_layer_Shape[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape/shape (Tens [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_2 (TensorFl [(None, 5, 5)]       0           invcov[0][0]                     \n",
      "                                                                 tf_op_layer_Reshape_2/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape (TensorFlow [(None, 5, 1)]       0           outputs[0][0]                    \n",
      "                                                                 tf_op_layer_Reshape/shape[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_1 (TensorFl [(None, 5, 1)]       0           state_true[0][0]                 \n",
      "                                                                 tf_op_layer_Reshape_1/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Transpose (TensorFl [(None, 5, 5)]       0           tf_op_layer_Reshape_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub (TensorFlowOpLa [(None, 5, 1)]       0           tf_op_layer_Reshape[0][0]        \n",
      "                                                                 tf_op_layer_Reshape_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2 (Tens [(None, 5, 1)]       0           tf_op_layer_Transpose[0][0]      \n",
      "                                                                 tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3/shape (Te [(3,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_3 (TensorFl [(None, 1, 5)]       0           tf_op_layer_BatchMatMulV2[0][0]  \n",
      "                                                                 tf_op_layer_Reshape_3/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_BatchMatMulV2_1 (Te [(None, 1, 1)]       0           tf_op_layer_Reshape_3[0][0]      \n",
      "                                                                 tf_op_layer_Sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4/shape (Te [(1,)]               0           tf_op_layer_strided_slice[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Reshape_4 (TensorFl [(None,)]            0           tf_op_layer_BatchMatMulV2_1[0][0]\n",
      "                                                                 tf_op_layer_Reshape_4/shape[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "add_loss (AddLoss)              (None,)              0           tf_op_layer_Reshape_4[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 6,922,805\n",
      "Trainable params: 6,922,805\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we want to check if a model has been saved due to previous training.\n",
    "# If so, then we read it in and continue training where it left off. Otherwise,\n",
    "# we define the model and start fresh. \n",
    "\n",
    "checkpoints_dir = '/home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5'\n",
    "\n",
    "# Look for most recent saved epoch\n",
    "epoch_loaded = -1\n",
    "if os.path.exists(checkpoints_dir):\n",
    "    for f in os.listdir(checkpoints_dir):\n",
    "        if f.startswith('model_epoch') and f.endswith('.h5'):\n",
    "            e = int(f[11:-3])\n",
    "            if e > epoch_loaded:\n",
    "                epoch_loaded = e\n",
    "                fname = checkpoints_dir+'/model_epoch%03d.h5' % epoch_loaded\n",
    "\n",
    "if epoch_loaded > 0:\n",
    "    print('Loading model: ' + fname)\n",
    "    model = load_model( fname )\n",
    "else:\n",
    "    print('Unable to find saved model. Will start from scratch')\n",
    "    model = DefineModel()\n",
    "    epoch_loaded = 0\n",
    "\n",
    "# Print summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "First I define the checkpoint routine that will save the full model after every epoch so we always have the latest model saved. It also removes the previous model since the disk space usage can get quite large otherwise.\n",
    "\n",
    "The \"EPOCHS\" and \"BS\" variables can be used to set the total number of epochs to train and the batch size respectively. Note that I only do a few epochs here since it prints a few lines for each which will blow up the output when the fit is done if a lot more are used. This at least proves that it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch000.h5\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Epoch 1/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 233196.3281 - mae: 15.5941 - mse: 878.3378 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch000.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch001.h5\n",
      "1/1 [==============================] - 0s 245ms/step - loss: 233196.3281 - mae: 15.5941 - mse: 878.3378 - accuracy: 1.0000 - val_loss: 204705.3438 - val_mae: 13.5846 - val_mse: 739.2723 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 232064.2969 - mae: 15.5926 - mse: 878.3093 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch001.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch002.h5\n",
      "1/1 [==============================] - 0s 228ms/step - loss: 232064.2969 - mae: 15.5926 - mse: 878.3093 - accuracy: 1.0000 - val_loss: 205371.3438 - val_mae: 13.5859 - val_mse: 739.2246 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 231101.2969 - mae: 15.5878 - mse: 878.1534 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch002.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch003.h5\n",
      "1/1 [==============================] - 0s 219ms/step - loss: 231101.2969 - mae: 15.5878 - mse: 878.1534 - accuracy: 1.0000 - val_loss: 203847.0781 - val_mae: 13.5800 - val_mse: 738.9827 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 229972.5781 - mae: 15.5866 - mse: 878.1493 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch003.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch004.h5\n",
      "1/1 [==============================] - 0s 234ms/step - loss: 229972.5781 - mae: 15.5866 - mse: 878.1493 - accuracy: 1.0000 - val_loss: 204545.6719 - val_mae: 13.5819 - val_mse: 738.8873 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 229147.3125 - mae: 15.5819 - mse: 877.9730 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch004.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch005.h5\n",
      "1/1 [==============================] - 0s 250ms/step - loss: 229147.3125 - mae: 15.5819 - mse: 877.9730 - accuracy: 1.0000 - val_loss: 203021.4531 - val_mae: 13.5757 - val_mse: 738.7056 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 228018.0469 - mae: 15.5812 - mse: 877.9700 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch005.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch006.h5\n",
      "1/1 [==============================] - 0s 247ms/step - loss: 228018.0469 - mae: 15.5812 - mse: 877.9700 - accuracy: 1.0000 - val_loss: 203479.6406 - val_mae: 13.5772 - val_mse: 738.5473 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 227141.2812 - mae: 15.5767 - mse: 877.8212 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch006.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch007.h5\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 227141.2812 - mae: 15.5767 - mse: 877.8212 - accuracy: 1.0000 - val_loss: 202068.7812 - val_mae: 13.5713 - val_mse: 738.4701 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 226138.7656 - mae: 15.5771 - mse: 877.8561 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch007.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch008.h5\n",
      "1/1 [==============================] - 0s 246ms/step - loss: 226138.7656 - mae: 15.5771 - mse: 877.8561 - accuracy: 1.0000 - val_loss: 202648.8125 - val_mae: 13.5731 - val_mse: 738.2516 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 225268.2812 - mae: 15.5714 - mse: 877.6656 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch008.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch009.h5\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 225268.2812 - mae: 15.5714 - mse: 877.6656 - accuracy: 1.0000 - val_loss: 201283.9531 - val_mae: 13.5674 - val_mse: 738.2274 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - ETA: 0s - loss: 224229.1875 - mae: 15.5725 - mse: 877.7225 - accuracy: 1.0000removing old model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch009.h5\n",
      "saving model: /home/davidl/work2/2020.04.30.trackingML/model_checkpoints_part5/model_epoch010.h5\n",
      "1/1 [==============================] - 0s 232ms/step - loss: 224229.1875 - mae: 15.5725 - mse: 877.7225 - accuracy: 1.0000 - val_loss: 201754.5938 - val_mae: 13.5689 - val_mse: 738.0228 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------\n",
    "# class checkpointModel\n",
    "#-----------------------------------------------------\n",
    "# There is a bug in keras that causes an error when trying to save a model\n",
    "# trained on multiple GPUs. The work around is to save the original model\n",
    "# at the end of every epoch using a callback. See\n",
    "#    https://github.com/keras-team/kersas/issues/8694\n",
    "if not os.path.exists(checkpoints_dir): os.mkdir(checkpoints_dir)\n",
    "class checkpointModel(Callback):\n",
    "    def __init__(self, model):\n",
    "        self.model_to_save = model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        myepoch = epoch_loaded + epoch +1\n",
    "        fname = checkpoints_dir+'/model_epoch%03d.h5' % myepoch\n",
    "        old_fname = checkpoints_dir+'/model_epoch%03d.h5' % (myepoch-1)\n",
    "        if os.path.exists( old_fname ):\n",
    "            print('removing old model: %s' % old_fname)\n",
    "            os.remove( old_fname )\n",
    "        print('saving model: %s' % fname)\n",
    "        self.model_to_save.save(fname)\n",
    "cbk = checkpointModel( model )\n",
    "\n",
    "cbk.on_epoch_end(-1)\n",
    "\n",
    "EPOCHS = 10\n",
    "BS     = 100\n",
    "\n",
    "# Inputs is actually a list of 3 inputs so we can pass in the inverse covariance\n",
    "# matrix. See DefineModel procedure above.\n",
    "x_inp       = df.iloc[:,:]\n",
    "y_true      = labelsdf.iloc[:, 1:6]   # Peel off only 5 state vector parameters\n",
    "invcov_true = labelsdf.iloc[:,21:46]  # Peel off 25 inverse covariance matrix parameters\n",
    "\n",
    "print(type(df.iloc[:,0:1]))\n",
    "print(type(labelsdf.iloc[:,0:1]))\n",
    "print(type(y_true))\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x = [x_inp, invcov_true, y_true],\n",
    "    y = y_true,\n",
    "    batch_size = BS,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[cbk],\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    initial_epoch = epoch_loaded,\n",
    "    use_multiprocessing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2020.06.02",
   "language": "python",
   "name": "venv_2020.06.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
