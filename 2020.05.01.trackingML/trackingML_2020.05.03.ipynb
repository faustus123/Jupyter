{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trackingML DL with GlueX Fall 2018 data part 2\n",
    "\n",
    "In this notebook I take the example from the toy4 problem (=ML Challenge 2) and make a complete example for fitting the state vector. This is not the final model and training that we want, but it lays out *a* working example that shows how to deal with a lot of technical details.\n",
    "\n",
    "In here I make a model that implements a common input section and then 5 separate \"legs\", one for each of the 5 state vector parameters. The final layer merges these all back into a single, 5-parameter output layer. Note that this does not try to include covariance values in the model output. I'll deal with that in the next part.\n",
    "\n",
    "A nice thing about this setup is that each parameter has its own dedicated part of the model. Thus, if one parameter needs more layers or a certain structure, it can be fine tuned without affecting the others.\n",
    "\n",
    "One major improvement here over the toy4 model is that the input data comes in CSV format that removes the need for a generator. This greatly simplifies the code at the expense of making the input features file 2.5 times bigger than raw EVIO data file (50GB vs. 20GB).\n",
    "\n",
    "Something else implemented here from before is the use of a customized layer that calculates a weighted average. In earlier toy model tests this showed significant improvement in accuracy. The hypothesis is that it includes a division operation which cannot be done with normal layers expect under special conditions. Division could be mimiced using lots of layers in a deeper network, but that would mean more parameters and longer training.\n",
    "\n",
    "This first section just reads in a portion of the training files and sets a few parameters used later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Number of input features per track: 5835\n",
      "Number of tracks read: 1000  ( 0.06% of total )\n",
      "Label Names: \n",
      "              event\n",
      "              q_over_pt, phi, tanl, D, z\n",
      "              cov_00, cov_01, cov_02, cov_03, cov_04\n",
      "              cov_11, cov_12, cov_13, cov_14, cov_22\n",
      "              cov_23, cov_24, cov_33, cov_34, cov_44\n",
      "              chisq, Ndof\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Reshape, Flatten, Input, Lambda\n",
    "from tensorflow.keras.optimizers import SGD, Adamax, Adadelta\n",
    "from tensorflow.keras.callbacks import Callback, TensorBoard\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.losses\n",
    "import tensorflow as tf\n",
    "\n",
    "TRAIN_FILE  = '/home/davidl/work2/2020.04.30.trackingML/trackingML_features.csv'\n",
    "LABELS_FILE = '/home/davidl/work2/2020.04.30.trackingML/trackingML_labels.csv'\n",
    "MAX_TRACKS  = 1000  # Number of tracks(lines) to read from training file\n",
    "\n",
    "GPUS   = 0  # 0=force CPU, otherwise, the number of GPUs to use\n",
    "Nouts  = 60 # For Lamda layers that use MyWeightedAvg()\n",
    "\n",
    "#------------- Define output bin values and ranges\n",
    "DMIN   = -12.0\n",
    "DMAX   =  12.0\n",
    "D_BINSIZE = (DMAX-DMIN)/Nouts\n",
    "\n",
    "PHIMIN   = -12.0\n",
    "PHIMAX   =  12.0\n",
    "PHI_BINSIZE = (PHIMAX-PHIMIN)/Nouts\n",
    "\n",
    "QOVERPt_MIN   = -12.0\n",
    "QOVERPt_MAX   =  12.0\n",
    "QOVERPt_BINSIZE = (QOVERPt_MAX-QOVERPt_MIN)/Nouts\n",
    "\n",
    "TANLMIN   = -10.0\n",
    "TANLMAX   =  10.0\n",
    "TANL_BINSIZE = (TANLMAX-TANLMIN)/Nouts\n",
    "\n",
    "ZMIN   = -10.0\n",
    "ZMAX   =  10.0\n",
    "Z_BINSIZE = (ZMAX-ZMIN)/Nouts\n",
    "#--------------\n",
    "\n",
    "# Get fraction of features file read so we can estimate fraction of data we're using\n",
    "percent_read = 0.0;\n",
    "with open(TRAIN_FILE) as f:\n",
    "    f.readline()  # skip header\n",
    "    for i in range(100): percent_read = percent_read + float(len(f.readline()) + 1)\n",
    "    percent_read = 100.0*percent_read/os.path.getsize(TRAIN_FILE)*MAX_TRACKS/100.0\n",
    "\n",
    "# NOTE: Only reading first few rows for now since it takes a long time to read entire file\n",
    "df       = pd.read_csv(TRAIN_FILE  , nrows=MAX_TRACKS)\n",
    "labelsdf = pd.read_csv(LABELS_FILE , nrows=MAX_TRACKS)\n",
    "\n",
    "NINPUTS = len(df.columns)\n",
    "\n",
    "print('\\n\\nNumber of input features per track: %d' % NINPUTS)\n",
    "print('Number of tracks read: %d  ( %3.2f%% of total )' % (len(df.index), percent_read))\n",
    "print('Label Names: ')\n",
    "print('              ' + ', '.join(labelsdf.columns[0:1]))\n",
    "print('              ' + ', '.join(labelsdf.columns[1:6]))\n",
    "print('              ' + ', '.join(labelsdf.columns[6:11]))\n",
    "print('              ' + ', '.join(labelsdf.columns[11:16]))\n",
    "print('              ' + ', '.join(labelsdf.columns[16:21]))\n",
    "print('              ' + ', '.join(labelsdf.columns[21:]))\n",
    "print('\\n')"
   ]
  },
  {
   "attachments": {
    "ModelDiagram.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8AAAAIcCAIAAAC2P1AsAABC1UlEQVR42u3dDZRddX3o/Vkakbbc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\nAElFTkSuQmCC\n"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Layer Definition\n",
    "\n",
    "This section defines the layers of the model. It actually just defines some procedures that aren't executed until a couple of cells later. (That is when any errors will come up.)\n",
    "\n",
    "To make things easier to maintain, different parts of the model are defined in different procedures. The structure is shown in the diagram below. Note that these make use of a Lambda layer which uses the MyWeightedAvg procedure defined at the bottom of the cell. Lamda's are nice for making simple custom layers without the complexity of full custom layers.\n",
    "\n",
    "![ModelDiagram.png](attachment:ModelDiagram.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "# DefineCommonModel\n",
    "#-----------------------------------------------------\n",
    "def DefineCommonModel(inputs):\n",
    "    x = Flatten(name='top_layer1')(inputs)\n",
    "    x = Dense(int(Nouts*5), name='common_layer1', activation='linear', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineDModel\n",
    "#-----------------------------------------------------\n",
    "def DefineDModel(inputs):\n",
    "    x = Dense(Nouts, name='D_output_dist', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='D_output', arguments={'binsize':D_BINSIZE, 'xmin':DMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefinePhiModel\n",
    "#-----------------------------------------------------\n",
    "def DefinePhiModel(inputs):\n",
    "    x = Dense(Nouts, name='phi_output_dist', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='phi_output', arguments={'binsize':PHI_BINSIZE, 'xmin':PHIMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Define_q_over_pt_Model\n",
    "#-----------------------------------------------------\n",
    "def Define_q_over_pt_Model(inputs):\n",
    "    x = Dense(Nouts, name='q_over_pt_output_dist', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='q_over_pt_output', arguments={'binsize':QOVERPt_BINSIZE, 'xmin':QOVERPt_MIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# Define_tanl_Model\n",
    "#-----------------------------------------------------\n",
    "def Define_tanl_Model(inputs):\n",
    "    x = Dense(Nouts, name='tanl_output_dist', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='tanl_output', arguments={'binsize':TANL_BINSIZE, 'xmin':TANLMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineZModel\n",
    "#-----------------------------------------------------\n",
    "def DefineZModel(inputs):\n",
    "    x = Dense(Nouts, name='z_output_dist', activation='relu', kernel_initializer=\"glorot_uniform\")(inputs)\n",
    "    x = Lambda(MyWeightedAvg, output_shape=(1,), name='z_output', arguments={'binsize':Z_BINSIZE, 'xmin':ZMIN})(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineCommonOutput\n",
    "#-----------------------------------------------------\n",
    "def DefineCommonOutput(inputs):\n",
    "    x = tf.keras.layers.concatenate( inputs )\n",
    "    x = Dense(5, name='outputs', activation='relu', kernel_initializer=\"glorot_uniform\")(x)\n",
    "    return x\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# MyWeightedAvg\n",
    "#\n",
    "# This is used by the final Lambda layer in each branch\n",
    "# of the network. It defines the formula for calculating\n",
    "# the weighted average of the inputs from the previous\n",
    "# layer.\n",
    "#-----------------------------------------------------\n",
    "def MyWeightedAvg(inputs, binsize, xmin):\n",
    "    ones = K.ones_like(inputs[0,:])                       # [1, 1, 1, 1....]   (size Nouts)\n",
    "    idx  = K.cumsum(ones)                                 # [1, 2, 3, 4....]   (size Nouts)\n",
    "    norm = K.sum(inputs, axis=1, keepdims=True)           # normalization of all outputs by batch. shape is 1D array of size batch (n.b. keepdims=True is critical!)\n",
    "    wsum = K.sum(idx*inputs, axis=1, keepdims=True)/norm  # array of size batch with weighted avg. of mean in units of bins (n.b. keepdims=True is critical!)\n",
    "    output = (binsize*(wsum-0.5)) + xmin                  # convert from bins to physical units (shape batch,1)\n",
    "\n",
    "    print('MyWeightedAvg:')\n",
    "    print('       binsize = %f' % binsize)\n",
    "    print('          xmin = %f' % xmin)\n",
    "    print('   input shape = %s' % str(inputs.shape))\n",
    "    print('  output shape = %s' % str(output.shape))\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "\n",
    "The full model is put together here using the parts defined in the previous cell. It also defines weights for the trivial loss function used. The weights are used here as a way of scaling the loss for each of the state parameters by $1/\\sigma_i$ to account for the different units and uncertainties. This is actually not going to be sufficient in the end where full custom loss function will be required. It at least gives a simple example that can be used for the this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------\n",
    "# DefineModel\n",
    "#-----------------------------------------------------\n",
    "# This is used to define the model. It is only called if no model\n",
    "# file is found in the model_checkpoints directory.\n",
    "def DefineModel():\n",
    "\n",
    "    # If GPUS==0 this will force use of CPU, even if GPUs are present\n",
    "    # If GPUS>1 this will force the CPU to serve as orchestrator\n",
    "    # If GPUS==1 this will do nothing, allowing GPU to act as its own orchestrator\n",
    "    if GPUS!=1: tf.device('/cpu:0')\n",
    "\n",
    "    # Here we build the network model.\n",
    "    # This model is made of multiple parts. The first handles the\n",
    "    # inputs and identifies common features. The rest are branches with\n",
    "    # each determining an output parameter from those features.\n",
    "    inputs         = Input(shape=(NINPUTS,), name='image_inputs')\n",
    "    commonmodel    = DefineCommonModel(inputs)\n",
    "    Dmodel         = DefinePhiModel(         commonmodel )\n",
    "    phimodel       = DefineDModel(           commonmodel )\n",
    "    q_over_ptmodel = Define_q_over_pt_Model( commonmodel )\n",
    "    tanlmodel      = Define_tanl_Model(      commonmodel )\n",
    "    zmodel         = DefineZModel(           commonmodel )\n",
    "    commonoutput   = DefineCommonOutput([Dmodel, phimodel, q_over_ptmodel, tanlmodel, zmodel])\n",
    "    model          = Model(inputs=inputs, outputs=commonoutput)\n",
    "\n",
    "    # Here we specify a different loss function for every output branch.\n",
    "    # We also specify a weight for each branch. The weights allow us to \n",
    "    # specify that it is more important to minimize certain losses more\n",
    "    # than others.\n",
    "    sigma_D = 0.011    # placeholder\n",
    "    sigma_phi = 0.011  # estimated resolution in degrees (from previous training)\n",
    "    sigma_q_over_pt = 0.011    # placeholder\n",
    "    sigma_tanl = 0.011    # placeholder\n",
    "    sigma_z   = 0.100  # estimated resolution in cm (from previous training)\n",
    "    \n",
    "    # These need to be replaced by custom loss functions that can calculate\n",
    "    # the sigmas based on the state vector.\n",
    "    lossWeights = {\n",
    "        'D_output'         :  1.0/(sigma_D*sigma_D),\n",
    "        'phi_output'       :  1.0/(sigma_phi*sigma_phi),\n",
    "        'q_over_pt_output' :  1.0/(sigma_q_over_pt*sigma_q_over_pt),\n",
    "        'tanl_output'      :  1.0/(sigma_tanl*sigma_tanl),\n",
    "        'z_output'         :  1.0/(sigma_z*sigma_z),\n",
    "    }\n",
    "    \n",
    "    # It makes it easier if the output of the model is a simple array of 5\n",
    "    # values corresponding to the values in the labels file, in the same\n",
    "    # order. This next bit is just so we can put the loss weights in a list\n",
    "    # of the right order.\n",
    "    outNames = ['D_output', 'phi_output', 'q_over_pt_output', 'tanl_output', 'z_output']  # names in order of model outputs\n",
    "    lossWeights_list = []\n",
    "    for n in outNames: lossWeights_list.append(lossWeights[n])\n",
    "\n",
    "    # Compile the model, possibly using multiple GPUs\n",
    "    opt = Adadelta(clipnorm=1.0)\n",
    "    if GPUS<=1 :\n",
    "        final_model = model\n",
    "    else:\n",
    "        final_model = multi_gpu_model( model, gpus=GPUS )\n",
    "\n",
    "    final_model.compile(loss='mse', loss_weights=[lossWeights_list], optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "    \n",
    "    return final_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load or Build model\n",
    "\n",
    "I have found in the past that it is often good to be able to load a model that has undergone some training and continue training it. In addition, it is useful if you can keep track of how many epochs total were used in the training. In this cell, I look for the most recent model file and load it, if found. If no model file is found, then the model is defined using the above routines.\n",
    "\n",
    "Note that at the end of this the \"epochs_loaded\" parameter will be set to the number of epochs completed already for this model (0 if it is new). This number is passed into the fit call later so it displays the right thing and, in turn, passes it to the routine that saves the model periodically so that it can name the file properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find saved model. Will start from scratch\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.400000\n",
      "          xmin = -12.000000\n",
      "   input shape = (?, 60)\n",
      "  output shape = (?, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.400000\n",
      "          xmin = -12.000000\n",
      "   input shape = (?, 60)\n",
      "  output shape = (?, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.400000\n",
      "          xmin = -12.000000\n",
      "   input shape = (?, 60)\n",
      "  output shape = (?, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.333333\n",
      "          xmin = -10.000000\n",
      "   input shape = (?, 60)\n",
      "  output shape = (?, 1)\n",
      "MyWeightedAvg:\n",
      "       binsize = 0.333333\n",
      "          xmin = -10.000000\n",
      "   input shape = (?, 60)\n",
      "  output shape = (?, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "image_inputs (InputLayer)       [(None, 5835)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "top_layer1 (Flatten)            (None, 5835)         0           image_inputs[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "common_layer1 (Dense)           (None, 300)          1750800     top_layer1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "phi_output_dist (Dense)         (None, 60)           18060       common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "D_output_dist (Dense)           (None, 60)           18060       common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output_dist (Dense)   (None, 60)           18060       common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output_dist (Dense)        (None, 60)           18060       common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "z_output_dist (Dense)           (None, 60)           18060       common_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "phi_output (Lambda)             (None, 1)            0           phi_output_dist[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "D_output (Lambda)               (None, 1)            0           D_output_dist[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "q_over_pt_output (Lambda)       (None, 1)            0           q_over_pt_output_dist[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "tanl_output (Lambda)            (None, 1)            0           tanl_output_dist[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "z_output (Lambda)               (None, 1)            0           z_output_dist[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 5)            0           phi_output[0][0]                 \n",
      "                                                                 D_output[0][0]                   \n",
      "                                                                 q_over_pt_output[0][0]           \n",
      "                                                                 tanl_output[0][0]                \n",
      "                                                                 z_output[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, 5)            30          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,841,130\n",
      "Trainable params: 1,841,130\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Here we want to check if a model has been saved due to previous training.\n",
    "# If so, then we read it in and continue training where it left off. Otherwise,\n",
    "# we define the model and start fresh. \n",
    "\n",
    "# Look for most recent saved epoch\n",
    "epoch_loaded = -1\n",
    "if os.path.exists('model_checkpoints'):\n",
    "    for f in os.listdir('model_checkpoints'):\n",
    "        if f.startswith('model_epoch') and f.endswith('.h5'):\n",
    "            e = int(f[11:-3])\n",
    "            if e > epoch_loaded:\n",
    "                epoch_loaded = e\n",
    "                fname = 'model_checkpoints/model_epoch%03d.h5' % epoch_loaded\n",
    "\n",
    "if epoch_loaded > 0:\n",
    "    print('Loading model: ' + fname)\n",
    "    model = load_model( fname )\n",
    "else:\n",
    "    print('Unable to find saved model. Will start from scratch')\n",
    "    model = DefineModel()\n",
    "    epoch_loaded = 0\n",
    "\n",
    "# Print summary of model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model\n",
    "\n",
    "First I define the checkpoint routine that will save the full model after every epoch so we always have the latest model saved. It also removes the previous model since the disk space usage can get quite large otherwise.\n",
    "\n",
    "The \"EPOCHS\" and \"BS\" variables can be used to set the total number of epochs to train and the batch size respectively. Note that I only do a few epochs here since it prints a few lines for each which will blow up the output when the fit is done if a lot more are used. This at least proves that it works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving model: model_checkpoints/model_epoch000.h5\n",
      "Train on 800 samples, validate on 200 samples\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/clip_ops.py:157: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/3\n",
      "removing old model: model_checkpoints/model_epoch000.h5\n",
      "saving model: model_checkpoints/model_epoch001.h5\n",
      "800/800 [==============================] - 1s 932us/sample - loss: 41217056.0000 - mean_absolute_error: 25.2073 - mean_squared_error: 6215.2788 - acc: 0.0088 - val_loss: 13691478.0000 - val_mean_absolute_error: 21.1145 - val_mean_squared_error: 2064.5908 - val_acc: 0.0350\n",
      "Epoch 2/3\n",
      "removing old model: model_checkpoints/model_epoch001.h5\n",
      "saving model: model_checkpoints/model_epoch002.h5\n",
      "800/800 [==============================] - 0s 449us/sample - loss: 41216136.0000 - mean_absolute_error: 25.2042 - mean_squared_error: 6215.1392 - acc: 0.0088 - val_loss: 13690752.0000 - val_mean_absolute_error: 21.1116 - val_mean_squared_error: 2064.4812 - val_acc: 0.0350\n",
      "Epoch 3/3\n",
      "removing old model: model_checkpoints/model_epoch002.h5\n",
      "saving model: model_checkpoints/model_epoch003.h5\n",
      "800/800 [==============================] - 0s 447us/sample - loss: 41215216.0000 - mean_absolute_error: 25.2013 - mean_squared_error: 6215.0015 - acc: 0.0088 - val_loss: 13690035.0000 - val_mean_absolute_error: 21.1088 - val_mean_squared_error: 2064.3730 - val_acc: 0.0350\n"
     ]
    }
   ],
   "source": [
    "#-----------------------------------------------------\n",
    "# class checkpointModel\n",
    "#-----------------------------------------------------\n",
    "# There is a bug in keras that causes an error when trying to save a model\n",
    "# trained on multiple GPUs. The work around is to save the original model\n",
    "# at the end of every epoch using a callback. See\n",
    "#    https://github.com/keras-team/kersas/issues/8694\n",
    "if not os.path.exists('model_checkpoints'): os.mkdir('model_checkpoints')\n",
    "class checkpointModel(Callback):\n",
    "    def __init__(self, model):\n",
    "        self.model_to_save = model\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        myepoch = epoch_loaded + epoch +1\n",
    "        fname = 'model_checkpoints/model_epoch%03d.h5' % myepoch\n",
    "        old_fname = 'model_checkpoints/model_epoch%03d.h5' % (myepoch-1)\n",
    "        if os.path.exists( old_fname ):\n",
    "            print('removing old model: %s' % old_fname)\n",
    "            os.remove( old_fname )\n",
    "        print('saving model: %s' % fname)\n",
    "        self.model_to_save.save(fname)\n",
    "cbk = checkpointModel( model )\n",
    "\n",
    "cbk.on_epoch_end(-1)\n",
    "\n",
    "EPOCHS = 3\n",
    "BS     = 1000\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x = df,\n",
    "    y = labelsdf.iloc[:, 1:6],  # Peel off only 5 state vector parameters\n",
    "    batch_size = BS,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=[cbk],\n",
    "    validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    initial_epoch = epoch_loaded,\n",
    "    use_multiprocessing=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
