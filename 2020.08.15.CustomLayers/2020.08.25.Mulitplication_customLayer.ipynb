{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplying 2 numbers with a custom layer\n",
    "\n",
    "In this notebook I create a simple 3-node network that multiplies 2 numbers. This implements an actual multiplication operation in a custom layer (as opposed to mimicing multiplication with a deep network). To make the layer more flexible, I give it trainable weights that are used as exponents for each of the input values. Thus, the single output from the layer is given by:\n",
    "\n",
    "$$\n",
    "y = b + \\prod_{i=0}^{N-1} x_{i}^{w_{i}}\n",
    "$$\n",
    "\n",
    "where:<br>\n",
    "$b$ is the bias (which I fix at 0 for this example)<br>\n",
    "$x_{i}$ are the inputs<br>\n",
    "$w_{i}$ are the weights<br>\n",
    "\n",
    "The custom layer accepts arguments for the number of inputs, an optional \"trainable\" argument for whether the weights should be adjusted during the training of the full model, and another optional \"initial_exponent\" argument so the caller can set the initial value of the exponents (i.e. weights). This is all done in the ProductLayer class defined in the following cell.\n",
    "\n",
    "In addition to defining the custom layer, I define a simple model that uses it and then tests it with a small set of inputs right at the end of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_shape=(None, 2)\n",
      "inputs.shape: (None, 2)\n",
      "self.w.shape: (1, 2)\n",
      "   tmp.shape: (None, 2)\n",
      " myout.shape: (None, 1)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "product_layer (ProductLayer) (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 3\n",
      "Trainable params: 2\n",
      "Non-trainable params: 1\n",
      "_________________________________________________________________\n",
      "inputs.shape: (3, 2)\n",
      "self.w.shape: (1, 2)\n",
      "   tmp.shape: (3, 2)\n",
      " myout.shape: (3, 1)\n",
      "tf.Tensor(\n",
      "[[82.810524]\n",
      " [82.810524]\n",
      " [82.810524]], shape=(3, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "NINPUTS = 2\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# ProductLayer\n",
    "#-----------------------------------------------------\n",
    "# This defines a layer that takes the product of the inputs,\n",
    "# each raised to the power of its weight. The trainable\n",
    "# parameter can be set to False to make it non-trainable.\n",
    "# n.b. If you make this trainable, the inputs cannot be\n",
    "# negative numbers!\n",
    "# See details on this in the following cell.\n",
    "class ProductLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, units=1, trainable=True, initial_exponent=2.01):\n",
    "        super(ProductLayer, self).__init__()\n",
    "        self.units            = units\n",
    "        self.trainable        = trainable\n",
    "        self.initial_exponent = initial_exponent\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        print('input_shape='+str(input_shape))\n",
    "        myinitializer   = tf.keras.initializers.Constant(self.initial_exponent)\n",
    "        self.w = self.add_weight(\n",
    "            shape       = (self.units, input_shape[-1]),\n",
    "            initializer = myinitializer,\n",
    "            trainable   = self.trainable,\n",
    "        )\n",
    "        self.b = self.add_weight(\n",
    "            shape       = (self.units,),\n",
    "            initializer = \"zeros\",\n",
    "            trainable   = False\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs has shape (None, 2)\n",
    "        # self.w has shape (1, 2)\n",
    "        # tmp has shape (None, 2)\n",
    "        # output has shape (None, 1)\n",
    "        tmp = K.pow(inputs, self.w)\n",
    "        myout = K.prod(tmp, keepdims=True, axis=1) + self.b\n",
    "        print('inputs.shape: ' + str(inputs.shape))\n",
    "        print('self.w.shape: ' + str(self.w.shape))\n",
    "        print('   tmp.shape: ' + str(tmp.shape))\n",
    "        print(' myout.shape: ' + str(myout.shape))\n",
    "        return myout\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Linear, self).get_config()\n",
    "        config.update({\"units\": self.units, \"trainable\": self.trainable, \"initial_exponent\": self.initial_exponent})\n",
    "        return config\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineModel\n",
    "#-----------------------------------------------------\n",
    "# This is used to define the model. It is only called if no model\n",
    "# file is found in the model_checkpoints directory.\n",
    "def DefineModel():\n",
    "\n",
    "    # Build the network model with 2 inputs and one output.\n",
    "    inputs = Input(shape=(NINPUTS,), name='inputs')\n",
    "    output = ProductLayer(1)(inputs)\n",
    "    model  = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    opt = Adadelta(clipnorm=1.0)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = DefineModel()\n",
    "model.summary()\n",
    "\n",
    "x = tf.ones((3,2), dtype=tf.dtypes.float32)*(3.0001)\n",
    "y = model(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakdown of ProductLayer\n",
    "\n",
    "The ProductLayer class implements a custom layer in Keras. It has 4 methods described below. \n",
    "\n",
    "1. **\\_\\_init\\_\\_()**: This is the standard python constructor which gets called when the object is created. If there are any options given when the object is instantiated, they will be passed in here. This basically needs to save them as part of the object so they can be used in the other callback methods where the actual work is done.\n",
    "\n",
    "2. **build()**: This is called automatically the first time the call() method is called. This is all handled by Keras as it is what actually calls \"call()\" and recogonizes it needs to call \"build()\" first. This method is responsible for declaring any \"weights\" in the layer. I quote \"weights\" since you may notice that the same add_weight() method is called to add the bias values. It is really a way of declaring to Keras the trainable values in the layer. The build() method is actually optional since you could define a layer that does not have any trainable weights. Note that in this example I initialize the bias weights to 0 and then set them as non-trainable. This really is really overkill as I could get the same affect by not adding any bias weights at all. I left it in though to emphasize that any number of \"weights\" could be added here.\n",
    "\n",
    "3. **call()**: This is called to create an output Tensor (with a capital-T) based on some given inputs. This is where I actually implement what math the layer will do. This is only called once when the model is compiled. It uses Keras backend functions to define the set of operations that should be performed on the inputs in order to produce the outputs. It does not actually perform those operations during the call. Since Keras+Tensorflow know the operations, it also knows their derivatives which it can chain together to backpropagate during training. Most of my time here is spent on checking the shapes of the inputs to each operation to make sure the automatic looping over nodes is done correctly. See more details below.\n",
    "\n",
    "4. **config()**: This is needed when saving the model so it can get the parameters needed to configure the layer when it is loaded later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### Explanation of lines in call()\n",
    "  \n",
    "  The call method() has only two lines of real content that define the operation. The only important thing in the *inputs* valriable is its shape. In the comments the shapes of the various variables are given. Some of these contain *None* which acts as a placeholder. When the training is done and an actual set of values is given, the *None* value will be replaced by the batch size. Thus, the *(None, 2)* shape of *inputs* indicates some arbitrary number of sets of inputs with each set containing 2 numbers. The *2* is because we defined the layer to have only 2 inputs in the model (see NINPUTS=2 at top). This meaningful line is:\n",
    "  \n",
    "    tmp = K.pow(inputs, self.w)\n",
    "\n",
    "This line takes the inputs and raises them to the powers given by the weights. Since this is a backend function, it will automatically do this for all sets of inputs in the batch. The variable *tmp* therefore has a shape *(None, 2)* where again, *None* is the placeholder for the batch size.\n",
    "\n",
    "    myout = K.prod(tmp, keepdims=True, axis=1) + self.b\n",
    "\n",
    "This line takes the product of each value in a set and then adds the bias. The two arguments *keepDims=True* and *axis=1* say not to multiply **ALL** of the numbers together, but only those within the same batch element. Specifically, only multiply values on the *1-th* axis and not on the *0-th* axis. The the output of the K.prod() call will have a shape of *(None, 1)*. The shape of self.b does not ha\n",
    "\n",
    "ve a *None* dimension, but Keras is smart enough to know that you want to add this one number to all of the values in the *(None,1)* Tensor returned by K.prod().\n",
    "\n",
    "The value of *myout* is returned and indeed, you can see that the output shape of the model summary is *(None, 1)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the model\n",
    "\n",
    "Below is some pretty standard code for generating a set of inputs(aka *features*) and labels. Note that for this example, the range of values of the inputs are all positive. This is because I allow the weights to be trained as floating point numbers and taking a negative number to a fractional power is undefined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Generate dataframes for features and labels\n",
    "#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X = []\n",
    "Z = []\n",
    "for x in np.arange(0.0, 10.1, 0.1):\n",
    "    for y in np.arange(0.0, 10.1, 0.1):\n",
    "        z = x*y\n",
    "        X.append([x,y])  # features\n",
    "        Z.append([z])    # labels\n",
    "\n",
    "df = pd.DataFrame(X, columns=['x', 'y'])\n",
    "labelsdf = pd.DataFrame(Z, columns=['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (1, 2)\n",
      "self.w.shape: (1, 2)\n",
      "   tmp.shape: (1, 2)\n",
      " myout.shape: (1, 1)\n",
      "WARNING:tensorflow:From /w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:297: setdiff1d (from tensorflow.python.ops.array_ops) is deprecated and will be removed after 2018-11-30.\n",
      "Instructions for updating:\n",
      "This op will be removed after the deprecation date. Please switch to tf.sets.difference().\n",
      "inputs.shape: (1, 2)\n",
      "self.w.shape: (1, 2)\n",
      "   tmp.shape: (1, 2)\n",
      " myout.shape: (1, 1)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Linear' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c777933cf16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multiply_model_customLayer01.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \"\"\"\n\u001b[1;32m   1051\u001b[0m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0;32m-> 1052\u001b[0;31m                     signatures, options)\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options)\u001b[0m\n\u001b[1;32m    133\u001b[0m           'or using `save_weights`.')\n\u001b[1;32m    134\u001b[0m     hdf5_format.save_model_to_hdf5(\n\u001b[0;32m--> 135\u001b[0;31m         model, filepath, overwrite, include_optimizer)\n\u001b[0m\u001b[1;32m    136\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     saved_model_save.save(model, filepath, overwrite, include_optimizer,\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_graph_network\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   2117\u001b[0m           \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2119\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2120\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2121\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/w/halld-scifs17exp/halld2/home/davidl/builds/Python_VENV/venv_2020.06.02/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-2e4b0b689aef>\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"trainable\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"initial_exponent\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_exponent\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Linear' is not defined"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100  # (in addition to anything already done)\n",
    "BS     = 1\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    x = df,\n",
    "    y = labelsdf,\n",
    "    batch_size = BS,\n",
    "    epochs=EPOCHS,\n",
    "    #validation_split=0.2,\n",
    "    shuffle=True,\n",
    "    verbose=0,\n",
    "    use_multiprocessing=False\n",
    ")\n",
    "\n",
    "model.save('multiply_model_customLayer01.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the result\n",
    "\n",
    "For this simple example, the exponents are initialized to 2.01, but the labels are generated assuming all are 1.0. This lets us verify that the training actually worked and found the correct values. Printing the weights below shows they both came out pretty close to 1.0. I should note that if I allow the bias to train as well, it will cause the training to take longer, but it will eventually get down close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers: print(layer.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An even simpler example using a Lambda layer\n",
    "\n",
    "The above is doing something pretty simple, but the definition of the ProductLayer class does seem kind of large for something that is essentially $x_{0}\\times x_{1}$. It has the benefit though of being something that could be expanded to a pretty complex formula. Suppose though that we wanted to instead create a model that did the same thing, but did not have any trainable weights. In this case we could use a Keras *Lambda* layer. For this, we just need to define a procedure that is essentially the *call()* method of *ProductLayer*.\n",
    "\n",
    "In the following cell, I define such a routine. Here, the exponents are hardcoded as 0.5, 2.0 just by way of example. This means the output of the layer will be the product of the square root of the first input and the square of the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Lambda\n",
    "#-----------------------------------------------------\n",
    "# MyProductLambda\n",
    "#-----------------------------------------------------\n",
    "def MyProductLambda(inputs):\n",
    "    tmp = K.pow(inputs, (0.5, 2.0))\n",
    "    return K.prod(tmp, keepdims=True, axis=1)\n",
    "\n",
    "#-----------------------------------------------------\n",
    "# DefineModelLambda\n",
    "#-----------------------------------------------------\n",
    "def DefineModelLambda():\n",
    "\n",
    "    # Build the network model with 2 inputs and one output.\n",
    "    inputs = Input(shape=(NINPUTS,), name='inputs')\n",
    "    output = Lambda(MyProductLambda, output_shape=(1,))(inputs)\n",
    "    model  = Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    opt = Adadelta(clipnorm=1.0)\n",
    "    model.compile(loss='mse', optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model_lambda = DefineModelLambda()\n",
    "model_lambda.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model. We give all of the inputs as \"4\" so sqrt(4)*4^2 = 32 which you can see \n",
    "x_lambda = tf.ones((3,2), dtype=tf.dtypes.float32)*(4.0)\n",
    "y_lambda = model_lambda(x_lambda)\n",
    "print(y_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_2020.06.02",
   "language": "python",
   "name": "venv_2020.06.02"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
